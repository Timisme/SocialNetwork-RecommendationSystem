{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DrBC_hw1",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMXvxee2F4P8"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8S0VfORGHDf",
        "outputId": "84fa4f77-db1b-4d44-e797-b5f79f9ba671"
      },
      "source": [
        "print(torch.__version__.split('+'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1.8.0', 'cu101']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTlnpsBgGq8U",
        "outputId": "fffc5608-6e47-4195-904c-0c7761f823fd"
      },
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-{torch.__version__.split('+')[0]}+cu101.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-{torch.__version__.split('+')[0]}+cu101.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-{torch.__version__.split('+')[0]}+cu101.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{torch.__version__.split('+')[0]}+cu101.html\n",
        "!pip install torch-geometric\n",
        "# !pip install networkx"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
            "Collecting torch-scatter\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_scatter-2.0.6-cp37-cp37m-linux_x86_64.whl (2.5MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.6MB 7.0MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.6\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
            "Collecting torch-sparse\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_sparse-0.6.9-cp37-cp37m-linux_x86_64.whl (1.5MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.5MB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
            "Collecting torch-cluster\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (1.0MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.0MB 6.1MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
            "Collecting torch-spline-conv\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (386kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 389kB 7.9MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/5c/3e95b76321fb14f24cc2ace392075717f645c4632e796ee0db1bc7d17231/torch_geometric-1.6.3.tar.gz (186kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 194kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.8.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.5)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.51.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 235kB 14.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Collecting ase\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/36/de17e79f29e06d9a92746d0dd9ec4636487ab03f6af10e78586aae533f7a/ase-3.21.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.2MB 17.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torch-geometric) (3.7.4.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric) (54.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ase->torch-geometric) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (1.3.1)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.6.3-cp37-none-any.whl size=322719 sha256=faac7afca1e3b93ebb938125eacbc982cd70e7e111f9e0e8007d5d4c98f85212\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/47/1e/0af8ce3e21783c3e584c22502011a3367c091694eebc50a971\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, rdflib, ase, torch-geometric\n",
            "Successfully installed ase-3.21.1 isodate-0.6.0 rdflib-5.0.0 torch-geometric-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGi58_rFWuXl"
      },
      "source": [
        "# ËÆÄÂèñË≥áÊñô"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fu9apyLAWwOp",
        "outputId": "dd998e53-8aac-4275-afcb-7c213cd16d95"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqvZfHzRLLIN"
      },
      "source": [
        "# *Ë≥áÊñôÂâµÂª∫*\n",
        "x: ÁâπÂæµÂêëÈáè\n",
        "y: È°ûÂà•\n",
        "edge_index: data format \n",
        "\n",
        "Initial feature\n",
        "dim : (num_nodes, 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-7338yBHHD5"
      },
      "source": [
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.utils import degree\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvq5lCubxCN2"
      },
      "source": [
        "## Èö®Ê©üÂúñ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXZMKaYEloLf"
      },
      "source": [
        "def syn_fetcher(n= 5000):\n",
        "  syn_data_list = list()\n",
        "  for i in range(30):\n",
        "    with open(f'/content/drive/MyDrive/python_data/Á§æÁæ§Á∂≤Ë∑ØËàáÊé®Ëñ¶Á≥ªÁµ±/hw1/Synthetic/{n}/{i}.txt', 'r') as f:\n",
        "      with open(f'/content/drive/MyDrive/python_data/Á§æÁæ§Á∂≤Ë∑ØËàáÊé®Ëñ¶Á≥ªÁµ±/hw1/Synthetic/{n}/{i}_score.txt', 'r') as f_score:\n",
        "        edge_list = [line.strip().split('\\t') for line in f.readlines()]\n",
        "        edge_list = [[int(edge) for edge in line] for line in edge_list]\n",
        "        edge_index = torch.tensor(edge_list, dtype=torch.long)\n",
        "        in_nodes = torch.tensor([edge[0] for edge in edge_list])\n",
        "        out_nodes = torch.tensor([edge[1] for edge in edge_list])\n",
        "        num_nodes = n\n",
        "        # data = Data(edge_index=edge_index.t().contiguous())\n",
        "        # in_nodes, out_nodes = data['edge_index']\n",
        "        nodes_degree = degree(in_nodes, num_nodes= num_nodes, dtype= torch.float) + degree(out_nodes, num_nodes= num_nodes, dtype= torch.float)\n",
        "        Xv = torch.tensor([[dv.item(), 1, 1] for dv in nodes_degree])\n",
        "        Yv = [float(line.strip().split('\\t')[1]) for line in f_score.readlines()]\n",
        "        data = Data(x= Xv, y= Yv, edge_index=edge_index.t().contiguous())\n",
        "        syn_data_list.append(data)\n",
        "  print('done!')\n",
        "  torch.cuda.empty_cache()\n",
        "  return syn_data_list"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVELYeU4IROj"
      },
      "source": [
        "# syn_data_list = syn_fetcher()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtW2VqobxEnr"
      },
      "source": [
        "## Real"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFU1Q5ubxGcn"
      },
      "source": [
        "def real_fetcher(name= 'com-youtube'):\n",
        "  real_data_list = list() \n",
        "  with open(f'/content/drive/MyDrive/python_data/Á§æÁæ§Á∂≤Ë∑ØËàáÊé®Ëñ¶Á≥ªÁµ±/hw1/Real/{name}.txt', 'r') as f:\n",
        "    with open(f'/content/drive/MyDrive/python_data/Á§æÁæ§Á∂≤Ë∑ØËàáÊé®Ëñ¶Á≥ªÁµ±/hw1/Real/{name}_score.txt', 'r') as f_score:\n",
        "      edge_list = [line.strip().split(' ') for line in f.readlines()]\n",
        "      edge_list = [[int(edge) for edge in line] for line in edge_list]\n",
        "      edge_index = torch.tensor(edge_list, dtype=torch.long)\n",
        "      in_nodes = torch.tensor([edge[0] for edge in edge_list])\n",
        "      out_nodes = torch.tensor([edge[1] for edge in edge_list])\n",
        "      num_nodes = max(torch.max(in_nodes).item(), torch.max(out_nodes).item()) + 1\n",
        "      print(f'num nodes: {num_nodes}')\n",
        "      # data = Data(edge_index=edge_index.t().contiguous())\n",
        "      # in_nodes, out_nodes = data['edge_index']\n",
        "      nodes_degree = degree(in_nodes, num_nodes= num_nodes, dtype= torch.float) + degree(out_nodes, num_nodes= num_nodes, dtype= torch.float)\n",
        "      Xv = torch.tensor([[dv.item(), 1, 1] for dv in nodes_degree])\n",
        "      Yv = [float(line.strip().split('\\t')[1]) for line in f_score.readlines()]\n",
        "      data = Data(x= Xv, y= Yv, edge_index=edge_index.t().contiguous())\n",
        "      real_data_list.append(data)\n",
        "\n",
        "  return real_data_list"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afl5h3AvtvKG"
      },
      "source": [
        "from torch_geometric.nn import MessagePassing\n",
        "import torch.nn as nn "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-brRJfEtozD"
      },
      "source": [
        "# DrBC\n",
        "\n",
        "1. The user only has to define the functions ùúô , i.e. message(), and ùõæ , i.e. update(), as well as the aggregation scheme to use, i.e. aggr=\"add\", aggr=\"mean\" or aggr=\"max\".\n",
        "\n",
        "2. tensors passed to propagate() can be mapped to the respective nodes ùëñ and ùëó by appending _i or _j to the variable name, .e.g. x_i and x_j. Note that we generally refer to ùëñ as the central nodes that aggregates information, and refer to ùëó as the neighboring nodes\n",
        "\n",
        "3. The normalization coefficients are derived by the node degrees deg(ùëñ) for each node ùëñ which gets transformed to 1/(deg(ùëñ)‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚àö‚ãÖdeg(ùëó)‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚Äæ‚àö) for each edge (ùëó,ùëñ)‚ààÓà±. The result is saved in the tensor norm of shape [num_edges, ] (step 3)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hf2EFbzCcmT"
      },
      "source": [
        "## Ê®°Âûã\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmbmchhyn1op"
      },
      "source": [
        "class DrBC(MessagePassing):\n",
        "  def __init__(self, out_channels= 128, num_layers= 5, init_out_channels= 3, aggr= 'add'):\n",
        "    super(DrBC,self).__init__(aggr= aggr)\n",
        "    self.out_channels= out_channels\n",
        "    self.num_layers= num_layers\n",
        "    self.W0 = nn.Linear(init_out_channels, out_channels)\n",
        "    self.W4 = nn.Linear(out_channels, out_channels)\n",
        "    self.W5 = nn.Linear(out_channels, 1)\n",
        "    self.GRU = torch.nn.GRUCell(input_size= out_channels, hidden_size= out_channels, bias= True)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    '''x: [num_nodes, init_dim] edge_index: [2, num_edges]'''\n",
        "\n",
        "    # Step2: Á∑öÊÄßËÆäÊèõ\n",
        "    first_embedding = torch.nn.ReLU()(self.W0(x))\n",
        "    '''Normalization'''\n",
        "    v_norm = torch.norm(first_embedding, dim= 1).view(-1,1)\n",
        "    first_embedding = first_embedding/v_norm\n",
        "\n",
        "    # Step3: Â∞çËÆäÊèõÂæåÁØÄÈªûÁâπÂæµÈÄ≤Ë°åÊ®ôÊ∫ñÂåñ\n",
        "    in_nodes, out_nodes = edge_index\n",
        "    in_degree = degree(in_nodes, num_nodes= x.size(0), dtype= torch.float) \n",
        "    out_degree = degree(out_nodes, num_nodes= x.size(0), dtype= torch.float)\n",
        "    deg = in_degree + out_degree \n",
        "    deg_inv_sqrt = (deg+1).pow(-0.5)\n",
        "    norm = deg_inv_sqrt[in_nodes] * deg_inv_sqrt[out_nodes]\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      if i == 0:\n",
        "        print('first layer message passing')\n",
        "        message = self.propagate(edge_index, x=first_embedding, norm= norm)\n",
        "        x = self.GRU(message, first_embedding) # [N, out_channels]\n",
        "        '''TODO Normalize x matrix by row'''\n",
        "        v_norm = torch.norm(x, dim= 1).view(-1,1)\n",
        "        x = x/v_norm\n",
        "        h = x.unsqueeze(dim= 1) # [N, 1, out_channels]\n",
        "      else:\n",
        "        '''ÈáãÊîæË®òÊÜ∂È´î'''\n",
        "        torch.cuda.empty_cache()\n",
        "        print(f'{i} layer message passing')\n",
        "        message = self.propagate(edge_index, x=x, norm= norm)\n",
        "        x = self.GRU(message, x)\n",
        "        v_norm = torch.norm(x, dim= 1).view(-1,1)\n",
        "        x = x/v_norm\n",
        "        h = torch.cat([h, x.unsqueeze(dim= 1)], dim= 1)\n",
        "    \n",
        "    '''ÈáãÊîæË®òÊÜ∂È´î'''\n",
        "    torch.cuda.empty_cache()\n",
        "    # z, _ = torch.max(h, dim= 1) # max_pooling layers\n",
        "    z = nn.AdaptiveAvgPool2d((1, self.out_channels))(h)\n",
        "    z = z.squeeze(dim= 1)\n",
        "    y = self.W4(z)\n",
        "    y = torch.nn.ReLU()(y)\n",
        "    y = self.W5(y)\n",
        "\n",
        "    return y\n",
        "  # self.propagate(edge_index, x=x, norm=norm) from MassagePassing Ë™øÁî® messageÂáΩÊï∏\n",
        "  def message(self, x_j, norm): \n",
        "    # x_j has shape [E, out_channels]\n",
        "    return norm.view(-1, 1) * x_j\n",
        "\n",
        "  def update(self,aggr_out):\n",
        "    return aggr_out\n",
        "\n",
        "  def pair_wise_topk(self, pred, target, k= 0.05):\n",
        "    # args: pred [V, 1] target [V, 1]\n",
        "    size = pred.size()[0]\n",
        "    pred_topk = torch.topk(pred, k= int(size*k), dim= 0).indices\n",
        "    tgt_topk = torch.topk(target, k= int(size*k), dim= 0).indices\n",
        "\n",
        "    return len(np.intersect1d(pred_topk.cpu(), tgt_topk.cpu()))/(size*k)\n",
        "  \n",
        "  def pair_kendall_tau(self, pred, target):\n",
        "\n",
        "    pred_rank = stats.rankdata(pred.flatten().data.tolist())\n",
        "    tgt_rank = stats.rankdata(target.flatten().data.tolist())\n",
        "    tau, p = stats.kendalltau(x= pred_rank, y= tgt_rank)\n",
        "\n",
        "    return tau"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWJuGFTvZCDl"
      },
      "source": [
        "# Ë®ìÁ∑¥\n",
        "\n",
        "1. Â∞áÊâÄÊúâË≥áÊñôLoadÈÄ≤‰æÜ\n",
        "2. random sample 5|V| nodes to form 5|V| node pairs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8ztIOHdo7qx"
      },
      "source": [
        "from torch.optim import Adam\n",
        "from torch.nn import BCEWithLogitsLoss, Sigmoid\n",
        "import numpy as np \n",
        "import scipy.stats as stats\n",
        "import networkx as nx\n",
        "import time "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSvJs2caZy4d",
        "outputId": "f96b21b2-189b-40c9-e2fd-a7250cab24ef"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(f'using {device}')\n",
        "\n",
        "# device = torch.device('cuda')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZZU92UZoVxb"
      },
      "source": [
        "## ÂèÉÊï∏Ë®≠ÂÆö"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeZcelf0p3lP"
      },
      "source": [
        "out_channels = 64\n",
        "lr= 1e-4\n",
        "batch_size= 8\n",
        "node_sampling = 5\n",
        "iteration = 160\n",
        "L = 5\n",
        "n = 2000\n",
        "k = 0.01"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaESBH5IWGLp"
      },
      "source": [
        "# model = DrBC(out_channels= out_channels, num_layers= L, init_out_channels= 3, aggr= 'add').to(device)\n",
        "# optimizer = Adam(model.parameters(), lr= lr)\n",
        "# criterion = BCEWithLogitsLoss(reduction= 'sum')\n",
        "# for name, param in model.named_parameters():\n",
        "#     if param.requires_grad:\n",
        "#         print(name) #param.data)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A35ZxW06obtg"
      },
      "source": [
        "## function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzeJ1Cl_AxXr"
      },
      "source": [
        "def test(model, data_list= None, k= 0.01):\n",
        "\n",
        "  model.eval()\n",
        "  topk_list = []\n",
        "  tau_list = []\n",
        "  time_list = []\n",
        "\n",
        "  for data in data_list:\n",
        "\n",
        "    with torch.no_grad():\n",
        "      st = time.time()\n",
        "      print('starting prediction...')\n",
        "      preds = model(data['x'].to(device), data['edge_index'].to(device))\n",
        "      print('prediction ends...')\n",
        "      en = time.time()\n",
        "      labels = torch.tensor(data['y'], dtype= torch.float).view(-1,1).to(device)\n",
        "\n",
        "      topk_list.append(model.pair_wise_topk(pred= preds, target= labels, k= k))\n",
        "      tau_list.append(model.pair_kendall_tau(pred= preds, target= labels))\n",
        "      time_list.append(round(en-st,2))\n",
        "  \n",
        "  print('-'*50)\n",
        "  print(f'time: {round(en-st,2)}')\n",
        "  print(f'Mean time: {round(np.mean(time_list), 3)}')\n",
        "  print(f'std time: {round(np.std(time_list), 3)}')\n",
        "  print(f'Mean topk: {round(np.mean(topk_list), 3)}')\n",
        "  print(f'std topk: {round(np.std(topk_list), 3)}')\n",
        "  print(f'Mean tau: {round(np.mean(tau_list), 3)}')\n",
        "  print(f'std tau: {round(np.std(tau_list), 3)}')\n",
        "  print(f'test done!!!!')\n",
        "  print('-'*50)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsqxFqvrWewM"
      },
      "source": [
        "def train(model, n):\n",
        "\n",
        "  model.train()\n",
        "  topk_list = []\n",
        "  tau_list = []\n",
        "\n",
        "  for epoch in range(iteration):\n",
        "\n",
        "    if ((epoch+1) % batch_size) == 0:\n",
        "      print(f'{epoch+1}th epoch...')\n",
        "    \n",
        "    '''ÁîüÊàêË®ìÁ∑¥Ë≥áÊñô'''\n",
        "\n",
        "    G = nx.generators.random_graphs.powerlaw_cluster_graph(n= n, m=4 ,p= 0.05)\n",
        "    # nodes = [x for x in G.nodes()]\n",
        "    edge_list = [x for x in G.edges()]\n",
        "    in_nodes = torch.tensor([x[0] for x in G.edges()])\n",
        "    out_nodes = torch.tensor([x[1] for x in G.edges()])\n",
        "    edge_index = torch.tensor(edge_list, dtype=torch.long)\n",
        "\n",
        "    nodes_degree = degree(in_nodes, num_nodes= n, dtype= torch.float) + degree(out_nodes, num_nodes= n, dtype= torch.float)\n",
        "    Xv = torch.tensor([[dv.item(), 1, 1] for dv in nodes_degree])\n",
        "    st = time.time()\n",
        "    Yv = list(nx.betweenness_centrality(G, k= int(0.5 * Xv.size(0)), normalized=True).values())\n",
        "    en = time.time()\n",
        "\n",
        "    data = Data(x= Xv, y= Yv, edge_index=edge_index.t().contiguous())\n",
        "\n",
        "    # print(f'bcË®àÁÆó: {en-st} s')\n",
        "    # st = time.time()\n",
        "\n",
        "    preds = model(data['x'].to(device), data['edge_index'].to(device))\n",
        "    labels = torch.tensor(data['y'], dtype= torch.float).view(-1,1).to(device)\n",
        "\n",
        "    '''metrics'''\n",
        "    topk_list.append(model.pair_wise_topk(pred= preds, target= labels, k= k))\n",
        "    tau_list.append(model.pair_kendall_tau(pred= preds, target= labels))\n",
        "\n",
        "    '''sample nodes to calc loss'''\n",
        "    V = data.num_nodes \n",
        "    src_node_ids = set(data['edge_index'][0].data.tolist())\n",
        "    tgt_node_ids = set(data['edge_index'][1].data.tolist())\n",
        "    src_sample_ids = np.random.choice(list(src_node_ids), size=5*V, replace=True)\n",
        "    tgt_sample_ids = np.random.choice(list(tgt_node_ids), size=5*V, replace=True)\n",
        "\n",
        "    input = preds[src_sample_ids] - preds[tgt_sample_ids]\n",
        "    target = labels[src_sample_ids] - labels[tgt_sample_ids]\n",
        "\n",
        "    loss = criterion(input=input, target=Sigmoid()(target))\n",
        "    loss.backward()\n",
        "\n",
        "    '''Ê¢ØÂ∫¶Á¥ØÁ©ç'''\n",
        "    if ((epoch+1) % batch_size) == 0:\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      print(f'Mean topk: {round(np.mean(topk_list),3)}')\n",
        "      print(f'Mean tau: {round(np.mean(tau_list),3)}')\n",
        "      topk_list = []\n",
        "      tau_list = []\n",
        "\n",
        "      test(model= model, data_list= syn_data_list)\n",
        "      model.train()\n",
        "\n",
        "    # if (epoch+1) % 20 == 0:\n",
        "    #   print(f'Mean topk: {round(np.mean(topk_list),3)}')\n",
        "    #   print(f'Mean tau: {round(np.mean(tau_list),3)}')\n",
        "    #   topk_list = []\n",
        "    #   tau_list = []\n",
        "\n",
        "    #   test(model= model, data_list= syn_data_list)\n",
        "    #   test(model= model, data_list= real_data_list)\n",
        "\n",
        "    #   model.train()\n",
        "  \n",
        "  print('training process done!!!')\n",
        "  return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXveWo-SEKnm"
      },
      "source": [
        "# Ë®ìÁ∑¥ÂèäÊ∏¨Ë©¶Ë≥áÊñô\n",
        "save Ë®ìÁ∑¥Â•ΩÁöÑmodel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA50EidYDbh3"
      },
      "source": [
        "# trained_model = train(model= model, n= n)\n",
        "# torch.save(trained_model, f'DrBC_{n}_{out_channels}.pt')\n",
        "# !cp -f DrBC_{n}_{out_channels}.pt '/content/drive/My Drive/python_data/Á§æÁæ§Á∂≤Ë∑ØËàáÊé®Ëñ¶Á≥ªÁµ±/hw1'"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk9mPWJIwn24"
      },
      "source": [
        "## Ê∏¨Ë©¶\n",
        "load Ë®ìÁ∑¥Â•ΩÁöÑmodel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFrjwKaVqAWt"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtSfZEPL-pXD"
      },
      "source": [
        "trained_model = torch.load(f'/content/drive/My Drive/python_data/Á§æÁæ§Á∂≤Ë∑ØËàáÊé®Ëñ¶Á≥ªÁµ±/hw1/DrBC_{n}_{out_channels}.pt', map_location=torch.device(device))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwss8nxr-yjL"
      },
      "source": [
        "## Syn data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8VasfAy93vP"
      },
      "source": [
        "# for n in [5000, 10000, 20000, 50000, 100000]:\n",
        "#   for k in [0.01]:\n",
        "    \n",
        "#     syn_data_list = syn_fetcher(n= n)\n",
        "#     test(model= trained_model.to(device), data_list= syn_data_list, k= k)\n",
        "#     print(f'k: {k}')\n",
        "#     print(f'n: {n}')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c18_k7ht-0gJ"
      },
      "source": [
        "## Real data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_D0ytyUm-uZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671533b3-90d2-42e0-9402-77265a9b6242"
      },
      "source": [
        "name = 'com-youtube'\n",
        "# name = 'amazon'\n",
        "# name = 'dblp'\n",
        "# name = 'com-lj'\n",
        "real_data_list = real_fetcher(name= name)\n",
        "test(model= trained_model.to(device), data_list= real_data_list, k= 0.1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num nodes: 1134890\n",
            "starting prediction...\n",
            "first layer message passing\n",
            "1 layer message passing\n",
            "2 layer message passing\n",
            "3 layer message passing\n",
            "4 layer message passing\n",
            "prediction ends...\n",
            "--------------------------------------------------\n",
            "time: 0.79\n",
            "Mean time: 0.79\n",
            "std time: 0.0\n",
            "Mean topk: 0.588\n",
            "std topk: 0.0\n",
            "Mean tau: 0.668\n",
            "std tau: 0.0\n",
            "test done!!!!\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5uCQEz7z82E"
      },
      "source": [
        "data = real_data_list[0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnkEfj_dz_Gn",
        "outputId": "d088793a-37f4-44a9-fbea-940ec99843b2"
      },
      "source": [
        "data"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(edge_index=[2, 2987624], x=[1134890, 3], y=[1134890])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ7NI_pwRj4W"
      },
      "source": [
        "# model.eval()\n",
        "# topk_list = []\n",
        "# tau_list = []\n",
        "# time_list = []\n",
        "\n",
        "# for data in data_list:\n",
        "\n",
        "#   with torch.no_grad():\n",
        "#     st = time.time()\n",
        "#     preds = model(data['x'].to(device), data['edge_index'].to(device))\n",
        "#     en = time.time()\n",
        "#     labels = torch.tensor(data['y'], dtype= torch.float).view(-1,1).to(device)\n",
        "\n",
        "#     topk_list.append(model.pair_wise_topk(pred= preds, target= labels, k= k))\n",
        "#     tau_list.append(model.pair_kendall_tau(pred= preds, target= labels))\n",
        "#     time_list.append(round(en-st,2))\n",
        "\n",
        "# print('-'*50)\n",
        "# print(f'time: {round(en-st,2)}')\n",
        "# print(f'Mean time: {round(np.mean(time_list), 3)}')\n",
        "# print(f'std time: {round(np.std(time_list), 3)}')\n",
        "# print(f'Mean topk: {round(np.mean(topk_list), 3)}')\n",
        "# print(f'std topk: {round(np.std(topk_list), 3)}')\n",
        "# print(f'Mean tau: {round(np.mean(tau_list), 3)}')\n",
        "# print(f'std tau: {round(np.std(tau_list), 3)}')\n",
        "# print(f'test done!!!!')\n",
        "# print('-'*50)"
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}