{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "165px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "RecSys_CF_MF_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICyWQKzdf2UK"
      },
      "source": [
        "import numpy as np\n",
        "# from scipy import spatial\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error \n",
        "# torch.manual_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EVbVzgEgep7",
        "outputId": "b4aece48-ad28-433e-8d53-5b85b45294d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRyVas1zgvhL"
      },
      "source": [
        "path = '/content/drive/MyDrive/python_data/社群網路與推薦系統/hw3/data/Movielens/user_movie.dat'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeRLV3a3f2UT"
      },
      "source": [
        "files = ['Douban_Book', 'Movielens', 'Yelp']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iqcbAUZf2UU"
      },
      "source": [
        "# with open(f'./data/Douban_Book/user_book.dat') as f:\n",
        "#     data = [list(map(int, line.strip().split('\\t'))) for line in f.readlines()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXg7LxXDf2UU"
      },
      "source": [
        "# User-Item matrix \n",
        "\n",
        "CF 的缺點：\n",
        "\n",
        "* 如果沒有用戶的歷史數據就沒辦法做任何推薦\n",
        "* 以及無論 user-based 或 item-based 都需要消耗大量的運算資源\n",
        "* 大部分用戶有評分紀錄的資料都只佔所有資料中的很小一部分，matrix 相當稀疏，很難找到相似的資料\n",
        "* 會有馬太效應，越熱門的物品越容易被推薦，所以通常都會降低熱門物品的權重\n",
        "\n",
        "user-based 考慮的是 user 和 user 之間的相似程度\n",
        "\n",
        "    給定一個用戶 A\n",
        "    計算用戶 A 跟其他所有用戶的相似度\n",
        "    找出最相似的 m 個用戶\n",
        "    再找出這些用戶有評分但是用戶 A 沒有評分的物品（也可以額外限制至少要幾個用戶有評分過）\n",
        "    以「相似用戶的相似度」和「該用戶對該物品的評分」來加權算出用戶 A 對這些未評分物品的評分\n",
        "    最後推薦給 A 評分最高的 n 個物品\n",
        "\n",
        "預測 user_4 對 item_a 的評分 =\n",
        "(user_4_user_1_sim x user_1_item_a_rating + user_4_user_3_sim x user_3_item_a_rating) / (user_4_user_1_sim + user_4_user_3_sim)\n",
        "\n",
        "user-based 的特點：\n",
        "\n",
        "* 適合 user 遠少於 item 的系統，相似度的計算量會較少\n",
        "* item 的時效性強、更多樣的系統，例如新聞、社交網站，適合用 user-based CF\n",
        "* 不容易給出推薦理由\n",
        "* 驚喜度較高"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAAvNFi9f2UX"
      },
      "source": [
        "## Filtering & Spliting\n",
        "filtering 部分要改\n",
        "* test split部分是對有評分的部分？\n",
        "* Subtract mean的部分是針對user-item matrix不是sim_matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkVE3o7sf2UY"
      },
      "source": [
        "class CF:\n",
        "    def __init__(self, path= './data/Douban_Book/user_book.dat'):\n",
        "        \n",
        "        \n",
        "        names = ['user_id', 'item_id', 'rating']\n",
        "        df = pd.read_csv(path, sep='\\t', names=names)\n",
        "        \n",
        "        '''filtering'''\n",
        "        grouped_df = df.groupby(['user_id'])['item_id'].count()\n",
        "        filtered_user_id = grouped_df[grouped_df>3].index\n",
        "        filtered_df = df.set_index('user_id').loc[filtered_user_id].reset_index()\n",
        "        \n",
        "        '''user_id to index_id'''\n",
        "        self.user_dict = dict()\n",
        "        for i, user_id in enumerate(filtered_user_id):\n",
        "            self.user_dict[user_id] = i \n",
        "        \n",
        "        self.n_user= filtered_df['user_id'].unique().shape[0]\n",
        "        self.n_item = filtered_df['item_id'].unique().shape[0]\n",
        "        self.data= np.array(filtered_df)\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "            \n",
        "    def k_fold_data_split(self):\n",
        "        \n",
        "        np.random.shuffle(self.data)\n",
        "        train_data = self.data[:int(0.7*len(self.data))]\n",
        "        val_data = self.data[int(0.7*len(self.data)):int(0.8*len(self.data))]\n",
        "        test_data = self.data[int(0.8*len(self.data)):]\n",
        "        return train_data, val_data, test_data\n",
        "    \n",
        "    def get_user_item_matrix(self):\n",
        "        \n",
        "        train_data, _, self.test_data= self.k_fold_data_split()\n",
        "        matrix = torch.zeros((self.n_user, self.n_item), dtype= float)\n",
        "        self.mask_matrix = torch.zeros((self.n_user, self.n_item), dtype= float).to(self.device)\n",
        "        \n",
        "        for info in train_data:\n",
        "            matrix[self.user_dict[info[0]], info[1]-1] = info[2]\n",
        "            self.mask_matrix[self.user_dict[info[0]], info[1]-1] = 1\n",
        "        \n",
        "        self.user_item_matrix = matrix \n",
        "        return matrix\n",
        "    \n",
        "    def get_similarity_matrix(self, method= 'cosine', kind= 'user', epsilon= 1e-9):\n",
        "        \n",
        "        user_item_matrix = self.get_user_item_matrix().to(self.device)\n",
        "        # similarity_matrix = torch.zeros((self.n_user, self.n_user), dtype= float)\n",
        "        if method == 'cosine':\n",
        "            # epsilon -> small number for handling dived-by-zero errors\n",
        "            if kind == 'user':\n",
        "#                 sim = user_item_matrix.dot(user_item_matrix.T) + epsilon\n",
        "                sim = torch.mm(user_item_matrix, user_item_matrix.t()) + epsilon\n",
        "            elif kind == 'item':\n",
        "                sim = user_item_matrix.T.dot(user_item_matrix) + epsilon\n",
        "            norms = torch.sqrt(torch.diagonal(sim))\n",
        "            sim_matrix = sim/norms/norms.t()\n",
        "            # adjusted_sim_matrix = sim_matrix - torch.mean(sim_matrix, dim= 1) #減去平均\n",
        "            return sim_matrix\n",
        "        # elif method == 'Spearman':\n",
        "          \n",
        "            \n",
        "    def k_nearest_neighbor(self, sim_matrix, user_id, item_id, k= 10):\n",
        "      # sim_matrix= self.similarity_matrix()\n",
        "      '''\n",
        "      sim_matrix: [n_user, n_user], sim_matrix[self.user_dict[user_id]]：[n_user, 1]\n",
        "      mask: n_user x n_item, mask[:, item_id]：[n_user, 1]\n",
        "      '''\n",
        "      top_k_neighbor_ids = torch.argsort(sim_matrix[self.user_dict[user_id]]*self.mask_matrix[:, item_id], dim= 0, descending=True)[1:k+1] #除了自己\n",
        "      return top_k_neighbor_ids\n",
        "    \n",
        "    def predict(self):\n",
        "      predicts = []\n",
        "      ratings = []\n",
        "      neighbor_dict = dict()\n",
        "      sim_matrix = self.get_similarity_matrix()\n",
        "      # unique_user_ids = list(set([info[0] for info in self.test_data]))\n",
        "      # for user_id in unique_user_ids:\n",
        "      #   neighbor_dict[user_id] = self.k_nearest_neighbor(sim_matrix= sim_matrix, user_id= user_id)\n",
        "\n",
        "      for (user_id, item_id, rating) in self.test_data:\n",
        "        # print(neighbor_dict[user_id]) #該user_id對應的k個最近鄰居\n",
        "        '''該user_id對應有對item評分的最近k個鄰居'''\n",
        "        k_neighbor_ids = self.k_nearest_neighbor(sim_matrix= sim_matrix, user_id= user_id, item_id= item_id)\n",
        "        neighbor_ratings = self.user_item_matrix[k_neighbor_ids].t()[item_id] #k個鄰居在item對應的評分\n",
        "        predict = torch.sum(neighbor_ratings).item()/len(neighbor_ratings)\n",
        "        predicts.append(predict)\n",
        "        ratings.append(rating)\n",
        "      return mean_squared_error(ratings, predicts) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRTVHqhc-jn8"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6iqnkDQ-jSi"
      },
      "source": [
        "# CF_obj= CF(path= path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3NMD8Xy2aW6"
      },
      "source": [
        "# CF_obj.predict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np2N7MazVugC"
      },
      "source": [
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBhGYaglVwMm"
      },
      "source": [
        "# Matrix Factorization\n",
        "\n",
        "n_latent factor k\n",
        "  input:\n",
        "  * user_factor_matrix p： [k, n_user]]\n",
        "  * item_factor_mat q：[k, n_item]\n",
        "  * r：mask_matrix\n",
        "  * y：rating matrix\n",
        "\n",
        "initialization：\n",
        "\n",
        "  * learning rate\n",
        "  * lambda (regularization) = beta\n",
        "  * iteration \n",
        "  * init for p, q：~N(0, 0.01)\n",
        "  * SGD for updating params \n",
        "\n",
        "Loss function：\n",
        "\n",
        "for every r(i, j)= 1, minimize [user_mat matmul item_mat.t() - rating_matrix) + two regularization function corresponding to user, item factor matrix, respectively. \n",
        "\n",
        "[圖片](https://i.imgur.com/WB6Xllg.png)\n",
        "\n",
        "Biases：\n",
        "\n",
        "* subtract global mean u\n",
        "* learn biases for user and items \n",
        "* rating = global mean + preference factor + item bias + user bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubtXnVFWFSdS"
      },
      "source": [
        "class user_item_matrix():\n",
        "  def __init__(self, path):\n",
        "    names = ['user_id', 'item_id', 'rating']\n",
        "    df = pd.read_csv(path, sep='\\t', names=names, usecols = [i for i in range(3)])\n",
        "    \n",
        "    '''filtering'''\n",
        "    grouped_df = df.groupby(['user_id'])['item_id'].count()\n",
        "    filtered_user_id = grouped_df[grouped_df>3].index\n",
        "    filtered_df = df.set_index('user_id').loc[filtered_user_id].reset_index()\n",
        "    \n",
        "    '''user_id to index_id'''\n",
        "    self.user_dict = dict()\n",
        "    for i, user_id in enumerate(filtered_user_id):\n",
        "        self.user_dict[user_id] = i \n",
        "    \n",
        "    self.n_user= filtered_df['user_id'].unique().shape[0]\n",
        "    self.n_item = filtered_df['item_id'].unique().shape[0]\n",
        "    self.data= [[self.user_dict[info[0]], info[1], info[2]] for info in np.array(filtered_df)]\n",
        "    self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "  def k_fold_data_split(self):\n",
        "    \n",
        "    np.random.shuffle(self.data)\n",
        "    train_data = self.data[:int(0.7*len(self.data))]\n",
        "    val_data = self.data[int(0.7*len(self.data)):int(0.8*len(self.data))]\n",
        "    test_data = self.data[int(0.8*len(self.data)):]\n",
        "    return train_data, val_data, test_data\n",
        "\n",
        "  def get_user_item_matrix(self):\n",
        "    \n",
        "    train_data, val_data, test_data= self.k_fold_data_split()\n",
        "    matrix = torch.zeros((self.n_user, self.n_item), dtype= float, device= self.device)\n",
        "    test_matrix = torch.zeros((self.n_user, self.n_item), dtype= float, device= self.device)\n",
        "    # mask_matrix = torch.zeros((self.n_user, self.n_item), dtype= float).to(self.device)\n",
        "    for info in train_data:\n",
        "      matrix[info[0], info[1]-1] = info[2]\n",
        "    for info in test_data:\n",
        "      test_matrix[info[0], info[1]-1] = info[2]\n",
        "    return matrix, test_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty1EW6HMVyb2"
      },
      "source": [
        "class MF(nn.Module):\n",
        "  def __init__(self, n_user, n_item, k, beta, device):\n",
        "    super(MF, self).__init__()\n",
        "    self.device = device\n",
        "    self.n_user= n_user\n",
        "    self.n_item= n_item\n",
        "    self.beta = beta\n",
        "    \"\"\"parameters | .to(device) creates new tensor so that the params cant be fetched from model.parameters()\"\"\"\n",
        "    self.b = \n",
        "    self.p = torch.nn.Parameter(torch.randn(size= (self.n_user, k), dtype= float, device= device))\n",
        "    self.q = torch.nn.Parameter(torch.randn(size= (self.n_item, k), dtype= float, device= device))\n",
        "    self.b_u = torch.nn.Parameter(torch.zeros(size=(self.n_user, 1), dtype= float, device= device))\n",
        "    self.b_i = torch.nn.Parameter(torch.zeros(size=(self.n_item, 1), dtype= float, device= device)) \n",
        "    # self.params = nn.ParameterList([self.p, self.q, self.b_u, self.b_i])\n",
        "  \n",
        "  def forward(self, b):\n",
        "    predict = b + self.b_u.repeat(1, self.n_item) + self.b_i.t().repeat(self.n_user, 1) + torch.matmul(self.p, self.q.t())\n",
        "    return predict\n",
        "\n",
        "  def loss_function(self, y, y_mask, mask_boolean, b, predict):\n",
        "\n",
        "    # mask_boolean = (y_mask > 0)\n",
        "\n",
        "    sse = torch.sum((torch.masked_select(y, mask_boolean) - torch.masked_select(predict, mask_boolean))**2)\n",
        "    p_norm = torch.norm(self.p, dim= 1).unsqueeze(dim= 1) #[n_user, 1]\n",
        "    q_norm = torch.norm(self.q, dim= 1).unsqueeze(dim= 1) #[n_item, 1]\n",
        "    sum_b_u = torch.sum((torch.masked_select(self.b_u.repeat(1, self.n_item), mask_boolean))**2)\n",
        "    sum_b_i = torch.sum((torch.masked_select(self.b_i.t().repeat(self.n_user, 1), mask_boolean))**2)\n",
        "    sum_b = (b**2) * torch.sum(y_mask)\n",
        "    sum_p_norm = torch.sum((torch.masked_select(p_norm.repeat(1, self.n_item), mask_boolean))**2)\n",
        "    sum_q_norm = torch.sum((torch.masked_select(q_norm.t().repeat(self.n_user, 1), mask_boolean))**2)\n",
        "\n",
        "    return 0.5*sse + self.beta * 0.5 * (sum_b_u + sum_b_i + sum_b + sum_p_norm + sum_q_norm)\n",
        "  \n",
        "  def RMSE(self, test_mat, test_mask, predict): \n",
        "    # test_mat: [n_user, n_item] float\n",
        "    # test_mask: [n_user, n_item] boolean \n",
        "    # predict: [n_user, n_item] float\n",
        "\n",
        "    return round(mean_squared_error(torch.masked_select(test_mat, test_mask).detach().cpu(), torch.masked_select(predict, test_mask).detach().cpu(), squared= False), 2)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbITGV52S4NU"
      },
      "source": [
        "## Main\n",
        "\n",
        "* 每次產生user_item_matrix皆會進行隨機split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmSTuqYpvBst"
      },
      "source": [
        "lr= 5e-2\n",
        "iteration = 100\n",
        "k= 4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1764t8AZS37H",
        "outputId": "eae8b7cc-38cb-457e-b63c-acd7253fdcf0"
      },
      "source": [
        "y, test_y= user_item_matrix(path= path).get_user_item_matrix()\n",
        "y_mask = torch.where(y==0, y, 1.)\n",
        "y_mask_boolean = (y > 0)\n",
        "test_mask = (test_y > 0)\n",
        "b = torch.sum(y.flatten())/torch.sum(y_mask)\n",
        "n_user, n_item = y.shape\n",
        "print(f'len of train_data|n_rating for training: {torch.sum(y_mask)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len of train_data|n_rating for training: 552228.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY-RwclgTFfI"
      },
      "source": [
        "model = MF(n_user= n_user, n_item= n_item, k=k, beta=2, device= device)\n",
        "# predict = model(user_item_matrix= matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88ZZafU7z_eu"
      },
      "source": [
        "# list(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7K_BiMA3Y1s"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLU-QOWfRe-J"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdJsa1K1uc9B",
        "outputId": "01e99415-477b-4950-c71d-fa8d7d94b816"
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "model.train()\n",
        "for i in range(iteration):\n",
        "  # print(f'{i}th iteration')\n",
        "  optimizer.zero_grad()\n",
        "  output = model(b= b)\n",
        "  # loss = model.loss_function(y= matrix, y_mask= y_mask, mask_boolean= y_mask_boolean, b= b, predict= output)\n",
        "  loss = nn.MSELoss()(torch.masked_select(output, y_mask_boolean), torch.masked_select(y, y_mask_boolean))\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  torch.cuda.empty_cache()\n",
        "  if (i+1)%10 == 0:\n",
        "    print(f'loss: {loss.item():.3f}')\n",
        "    print(model.RMSE(test_mat= test_y, test_mask= test_mask, predict= output))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 4.609\n",
            "2.15\n",
            "loss: 4.604\n",
            "2.15\n",
            "loss: 4.599\n",
            "2.15\n",
            "loss: 4.594\n",
            "2.14\n",
            "loss: 4.589\n",
            "2.14\n",
            "loss: 4.583\n",
            "2.14\n",
            "loss: 4.578\n",
            "2.14\n",
            "loss: 4.573\n",
            "2.14\n",
            "loss: 4.568\n",
            "2.14\n",
            "loss: 4.563\n",
            "2.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ur0gHbpSwp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3156c9ba-8be1-4f8b-d4f4-1b631b06affe"
      },
      "source": [
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.6009, 4.7401, 3.7409,  ..., 4.4466, 5.0856, 7.3598],\n",
              "        [4.0829, 5.3592, 4.4615,  ..., 3.6873, 6.0461, 5.9408],\n",
              "        [4.7636, 3.0251, 4.8330,  ..., 6.7923, 1.7126, 3.4029],\n",
              "        ...,\n",
              "        [5.1858, 4.9946, 5.6265,  ..., 4.2929, 6.3073, 3.7461],\n",
              "        [2.7848, 4.6068, 3.1156,  ..., 5.2084, 1.5004, 7.1326],\n",
              "        [4.3528, 2.6998, 3.8131,  ..., 4.0002, 3.7332, 2.2705]],\n",
              "       device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zDS4joxTbi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59c19cca-eacc-4cb6-ba2a-5c84fb268ccf"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [4., 0., 3.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDIbCZ48TdUB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}