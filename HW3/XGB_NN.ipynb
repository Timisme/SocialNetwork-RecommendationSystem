{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGB_NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOdNKPZZEs08",
        "outputId": "dc81d6c7-f020-4ae2-d75f-c286a7615781"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error \n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.linear_model.logistic import LogisticRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "import torch \n",
        "import torch.nn as nn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paxSudysGa7s"
      },
      "source": [
        "folder = ['Movielens/user_movie.dat', 'Yelp/user_business.dat']\n",
        "i_data = 0\n",
        "# user_item_path = '/content/drive/MyDrive/python_data/社群網路與推薦系統/hw3/data/Movielens/user_movie.dat'\n",
        "user_item_path = '/content/drive/MyDrive/python_data/社群網路與推薦系統/hw3/data/' + folder[i_data]\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DXZ0_JsGfXD"
      },
      "source": [
        "def get_feature(path):\n",
        "  names = ['id', 'feature_id']\n",
        "  df = pd.read_csv(path, sep= '\\t', names= names)\n",
        "  n = int(df['id'].max())\n",
        "  n_feature = int(df['feature_id'].max())\n",
        "  feature_mat = torch.zeros(size= (n, n_feature), dtype= torch.float, device= device)\n",
        "  for i, row in df.iterrows():\n",
        "    feature_mat[int(row['id'])-1, int(row['feature_id'])-1] = 1 \n",
        "  return feature_mat"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCFQM3mkGfZS"
      },
      "source": [
        "item_feature_mats = []\n",
        "user_feature_mats = []\n",
        "folder = '/content/drive/MyDrive/python_data/社群網路與推薦系統/hw3/data/Movielens/'\n",
        "for file in ['movie_genre']:\n",
        "  path = folder + file + '.dat'\n",
        "  item_feature_mat = get_feature(path= path)\n",
        "  item_feature_mats.append(item_feature_mat)\n",
        "for file in ['user_age', 'user_occupation']:\n",
        "  path = folder + file + '.dat'\n",
        "  user_feature_mat = get_feature(path= path)\n",
        "  user_feature_mats.append(user_feature_mat)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADps_TnEGfbU",
        "outputId": "2bd4ca87-46aa-44ef-eb76-13d71008ede7"
      },
      "source": [
        "item_feature_mat = torch.cat(item_feature_mats, dim= 1)\n",
        "user_feature_mat = torch.cat(user_feature_mats, dim= 1)\n",
        "print(f'item feature mat: {item_feature_mat.shape}')\n",
        "print(f'user feature mat: {user_feature_mat.shape}')\n",
        "n_user = user_feature_mat.shape[0]\n",
        "n_item = item_feature_mat.shape[0]\n",
        "d = n_item + item_feature_mat.shape[1] + n_user + user_feature_mat.shape[1]\n",
        "print(f'd: {d}')\n",
        "\n",
        "item_feature_len = [mat.shape[1] for mat in item_feature_mats]\n",
        "user_feature_len = [mat.shape[1] for mat in user_feature_mats]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item feature mat: torch.Size([1682, 18])\n",
            "user feature mat: torch.Size([943, 29])\n",
            "d: 2672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOJCCeBxGfdH"
      },
      "source": [
        "rows = []\n",
        "y= []\n",
        "with open(user_item_path, 'r') as f:\n",
        "  for line in f.readlines():\n",
        "    user_temp = torch.zeros(size= (1, n_user), dtype= torch.float, device= device)\n",
        "    item_temp = torch.zeros(size= (1, n_item), dtype= torch.float, device= device)\n",
        "    if i_data == 0:\n",
        "      user_id, item_id, rating, _= line.strip().split('\\t')\n",
        "    elif i_data == 1:\n",
        "      user_id, item_id, rating = line.strip().split('\\t')\n",
        "    user_temp[0,int(user_id)-1] = 1\n",
        "    item_temp[0,int(item_id)-1] = 1\n",
        "    row = torch.cat([user_temp, item_temp, user_feature_mat[int(user_id)-1].unsqueeze(dim= 0), item_feature_mat[int(item_id)-1].unsqueeze(dim= 0)], dim= 1)\n",
        "    rows.append(row)\n",
        "    y.append(int(rating))\n",
        "\n",
        "X = torch.cat(rows, dim= 0)\n",
        "y = torch.tensor(y, dtype=torch.float)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEXM6zu8GubK"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDmhGCVoGffw"
      },
      "source": [
        "class XGB_NN(nn.Module):\n",
        "  def __init__(self, fields, XGB_dim= 10, k= 10, hidden_dims= [16, 16], dropout= 0, n_class= 1):\n",
        "    super(XGB_NN, self).__init__()\n",
        "    self.fields = fields \n",
        "    self.k = k \n",
        "    self.hidden_dims = hidden_dims\n",
        "\n",
        "    \"\"\"FM\"\"\"\n",
        "    d = sum(fields)\n",
        "    self.FM_w = nn.Linear(d, 1, bias= False)\n",
        "    self.embedding_ws = nn.ModuleList()\n",
        "    for i in fields:\n",
        "      self.embedding_ws.append(nn.Linear(i, k, bias= False))\n",
        "    \n",
        "    \"\"\"DNN\"\"\"\n",
        "    layers = []\n",
        "    input_dim = XGB_dim\n",
        "\n",
        "    for hidden_dim in hidden_dims:\n",
        "      layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "      layers.append(nn.BatchNorm1d(hidden_dim))\n",
        "      layers.append(nn.ReLU())\n",
        "      layers.append(nn.Dropout(p=dropout))\n",
        "      input_dim = hidden_dim\n",
        "    \n",
        "    layers.append(nn.Linear(hidden_dims[-1], n_class))\n",
        "    self.dnn = nn.Sequential(*layers)\n",
        "\n",
        "  def Dense_Embedding(self, X):\n",
        "    es = []\n",
        "    start= 0\n",
        "    for i, field in enumerate(self.fields):\n",
        "      ei = self.embedding_ws[i](X[:, start:start+field]).unsqueeze(dim= 1) # ei: [n, 1, k]\n",
        "      # ei = torch.matmul(X[:, start:start+field], self.embedding_ws[i]).unsqueeze(dim= 1) # ei: [n, 1, k]\n",
        "      start += field\n",
        "      es.append(ei)\n",
        "\n",
        "    return torch.cat(es, dim= 1) # [n, n_fields, k]  \n",
        "\n",
        "  \n",
        "  def FM(self, X):\n",
        "\n",
        "    sum_of_square = torch.sum(X, dim= 1)**2 #[n, k]\n",
        "    square_of_sum = torch.sum(X**2, dim= 1)\n",
        "    ix = sum_of_square - square_of_sum    \n",
        "    return 0.5 * torch.sum(ix, dim= 1, keepdim= True)\n",
        "\n",
        "  def XGB_DNN(self, XGB_embedding):\n",
        "    X = self.dnn(XGB_embedding)\n",
        "    return X\n",
        "  \n",
        "  def forward(self, X, XGB_embedding):\n",
        "\n",
        "    dense_X = self.Dense_Embedding(X)\n",
        "    FM_y = self.FM(dense_X)\n",
        "    DNN_y = self.XGB_DNN(XGB_embedding)\n",
        "    y = self.FM_w(X) + FM_y + DNN_y\n",
        "\n",
        "    # return nn.Sigmoid()(y)\n",
        "    return nn.ReLU()(y)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei3hesQiGfh7"
      },
      "source": [
        "def XGB(x_train, y_train, n_estimator, depth):\n",
        "    # xgb = XGBClassifier(n_estimators= n_estimator, max_depth= depth, n_jobs= -1, objective= 'multi:softmax', num_class= 5, booster= 'gbtree', random_state= 42)\n",
        "    xgb= XGBRegressor(n_estimators= n_estimator, max_depth= depth, n_jobs= -1, andom_state= 42, objective= \"reg:squarederror\")\n",
        "    xgb.fit(x_train, y_train)\n",
        "    \n",
        "    \"\"\"X：{array-like, sparse matrix} of shape (n_samples, n_features)\"\"\"\n",
        "    output = xgb.apply(x_train) # Shape: [n_interaction, n_estimator * n_class]\n",
        "\n",
        "    \"\"\"One Hot Encoding\"\"\"\n",
        "    # encoder = OneHotEncoder(sparse=False).fit(output)\n",
        "    # embedding = encoder.transform(output)\n",
        "    # print(embedding.shape)\n",
        "    # print(embedding)\n",
        "    # return xgb, encoder, torch.tensor(embedding, dtype= torch.float)\n",
        "    return xgb, torch.tensor(output, dtype= torch.float)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9KQ1iuNMiAi"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fERQlAgBMjgn",
        "outputId": "d6b07802-afc3-44f8-ff52-ea22f7c21938"
      },
      "source": [
        "fields = [n_user, n_item] + user_feature_len + item_feature_len\n",
        "print(fields)\n",
        "\n",
        "k = 10\n",
        "hidden_dims = [32, 32]\n",
        "lr = 1e-2\n",
        "p = 0\n",
        "n_estimator= 10\n",
        "depth= 5\n",
        "\n",
        "test_kf = KFold(n_splits=5, shuffle= True, random_state=42)\n",
        "val_kf = KFold(n_splits=8, shuffle= True, random_state=42)\n",
        "\n",
        "model = XGB_NN(fields= fields, XGB_dim= n_estimator, k= k, hidden_dims= hidden_dims, dropout= p).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[943, 1682, 8, 21, 18]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcqN0oTsMoQ7",
        "outputId": "72b2dd42-5416-4e2d-e12b-0f7ee972392d"
      },
      "source": [
        "RMSEs = []\n",
        "for rest_indice, test_indice in test_kf.split(X):\n",
        "  rest_X, rest_y = X[rest_indice], y[rest_indice]\n",
        "  test_X = X[test_indice]\n",
        "\n",
        "  for train_indice, val_indice in val_kf.split(rest_X):\n",
        "    train_X, val_X = rest_X[train_indice], rest_X[val_indice]\n",
        "    train_y = rest_y[train_indice]\n",
        "\n",
        "    # xgb, encoder, XGB_embedding = XGB(train_X, train_y, n_estimator= n_estimator, depth= depth)\n",
        "    xgb, XGB_embedding = XGB(train_X, train_y, n_estimator= n_estimator, depth= depth)\n",
        "    # print(XGB_embedding.shape)\n",
        "    '''training process'''\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X= train_X, XGB_embedding= XGB_embedding)\n",
        "    loss = criterion(output.squeeze(dim= 1).cpu(), y[train_indice])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    out = output.squeeze(dim= 1).detach().cpu()\n",
        "\n",
        "  '''testing process'''\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    # xgb_output= xgb.apply(X= test_X)\n",
        "    # embedding = encoder.transform(xgb_output)\n",
        "    embedding = xgb.apply(test_X)\n",
        "    output = model(X= test_X, XGB_embedding= torch.tensor(embedding, dtype= torch.float))\n",
        "    out = output.squeeze(dim= 1).detach().cpu()\n",
        "    rmse = mean_squared_error(out, y[test_indice], squared= False)\n",
        "    RMSEs.append(rmse)  \n",
        "\n",
        "print(f'avg RMSEs: {round(np.mean(RMSEs), 2)}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "avg RMSEs: 1.5499999523162842\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}