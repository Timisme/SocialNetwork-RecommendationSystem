{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xDeepFM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzX1oCeYi1qq",
        "outputId": "ecc8be3b-50cd-4cd0-b533-5ce6f4f78428"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error \n",
        "from sklearn.model_selection import KFold \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb8ec0a8b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37-_xPVGIc3S"
      },
      "source": [
        "# Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQBCsMbaIDnt"
      },
      "source": [
        "user_item_path = '/content/drive/MyDrive/python_data/社群網路與推薦系統/hw3/data/Movielens/user_movie.dat'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7R5F5rFIF7o"
      },
      "source": [
        "def get_feature(path):\n",
        "  names = ['id', 'feature_id']\n",
        "  df = pd.read_csv(path, sep= '\\t', names= names)\n",
        "  n = int(df['id'].max())\n",
        "  n_feature = int(df['feature_id'].max())\n",
        "  feature_mat = torch.zeros(size= (n, n_feature), dtype= torch.float, device= device)\n",
        "  for i, row in df.iterrows():\n",
        "    feature_mat[int(row['id'])-1, int(row['feature_id'])-1] = 1 \n",
        "  return feature_mat"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_pPZgEMIF98"
      },
      "source": [
        "item_feature_mats = []\n",
        "user_feature_mats = []\n",
        "folder = '/content/drive/MyDrive/python_data/社群網路與推薦系統/hw3/data/Movielens/'\n",
        "for file in ['movie_genre']:\n",
        "  path = folder + file + '.dat'\n",
        "  item_feature_mat = get_feature(path= path)\n",
        "  item_feature_mats.append(item_feature_mat)\n",
        "for file in ['user_age', 'user_occupation']:\n",
        "  path = folder + file + '.dat'\n",
        "  user_feature_mat = get_feature(path= path)\n",
        "  user_feature_mats.append(user_feature_mat)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7hgXe-mIGAJ",
        "outputId": "0f41f7fa-de08-4999-80a9-147cf5c0bcfd"
      },
      "source": [
        "item_feature_mat = torch.cat(item_feature_mats, dim= 1)\n",
        "user_feature_mat = torch.cat(user_feature_mats, dim= 1)\n",
        "print(f'item feature mat: {item_feature_mat.shape}')\n",
        "print(f'user feature mat: {user_feature_mat.shape}')\n",
        "n_user = user_feature_mat.shape[0]\n",
        "n_item = item_feature_mat.shape[0]\n",
        "d = n_item + item_feature_mat.shape[1] + n_user + user_feature_mat.shape[1]\n",
        "print(f'd: {d}')\n",
        "\n",
        "item_feature_len = [mat.shape[1] for mat in item_feature_mats]\n",
        "user_feature_len = [mat.shape[1] for mat in user_feature_mats]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item feature mat: torch.Size([1682, 18])\n",
            "user feature mat: torch.Size([943, 29])\n",
            "d: 2672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyKrCoXLIGCP"
      },
      "source": [
        "rows = []\n",
        "y= []\n",
        "with open(user_item_path, 'r') as f:\n",
        "  for line in f.readlines():\n",
        "    user_temp = torch.zeros(size= (1, n_user), dtype= torch.float, device= device)\n",
        "    item_temp = torch.zeros(size= (1, n_item), dtype= torch.float, device= device)\n",
        "    user_id, item_id, rating, _= line.strip().split('\\t')\n",
        "    user_temp[0,int(user_id)-1] = 1\n",
        "    item_temp[0,int(item_id)-1] = 1\n",
        "    row = torch.cat([user_temp, item_temp, user_feature_mat[int(user_id)-1].unsqueeze(dim= 0), item_feature_mat[int(item_id)-1].unsqueeze(dim= 0)], dim= 1)\n",
        "    rows.append(row)\n",
        "    y.append(int(rating))\n",
        "\n",
        "X = torch.cat(rows, dim= 0)\n",
        "y = torch.tensor(y, dtype=torch.float)\n",
        "# encoder = OneHotEncoder(sparse= False)\n",
        "# y_onehot = encoder.fit_transform(y.view(-1,1))\n",
        "# y_onehot = torch.tensor(y_onehot, dtype=torch.float) # tensor"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8GWqQmyIaiM"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo2uCAWEuqmS"
      },
      "source": [
        "class Dense_Embedding(nn.Module):\n",
        "  def __init__(self, fields, D):\n",
        "    super(Dense_Embedding, self).__init__()\n",
        "    self.fields= fields \n",
        "    self.embedding_ws = nn.ParameterList([nn.Parameter(torch.randn(size= (i, D), dtype=torch.float, device= device)) for i in fields])\n",
        "\n",
        "  def forward(self, X): #[batch_size, d]\n",
        "    es = []\n",
        "    start= 0\n",
        "    for i, field in enumerate(self.fields):\n",
        "      # ei = self.embedding_ws[i](X[:, start:start+field]).unsqueeze(dim= 1) # ei: [n, 1, D]\n",
        "      ei = torch.matmul(X[:, start:start+field], self.embedding_ws[i]).unsqueeze(dim= 1) # ei: [n, 1, D]\n",
        "      start += field\n",
        "      es.append(ei)\n",
        "    return torch.cat(es, dim= 1) # [n, n_fields, D]  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0trKSHVjZHq"
      },
      "source": [
        "\"\"\"\n",
        "  Input shape\n",
        "    - 3D tensor with shape: ``(batch_size, field_size, embedding_size)``.\n",
        "  Output shape\n",
        "    - 2D tensor with shape: ``(batch_size, featuremap_num)`` ``featuremap_num = sum(layer_size)`` .\n",
        "  Arguments\n",
        "    - **field_size** : Positive integer, number of feature groups.\n",
        "    - **layer_size** : list of int.Feature maps in each layer.\n",
        "    - **activation** : activation function name used on feature maps.\n",
        "    - **split_half** : bool.if set to False, half of the feature maps in each hidden will connect to output unit.\n",
        "    - **seed** : A Python integer to use as random seed.\n",
        "\"\"\"\n",
        "\n",
        "class CIN(nn.Module):\n",
        "  def __init__(self, field_size, layer_size=(128, 128)):\n",
        "    super(CIN, self).__init__()\n",
        "    self.layer_size = layer_size\n",
        "    self.field_nums = [field_size]\n",
        "    self.activation = nn.ReLU()\n",
        "\n",
        "    self.conv1ds = nn.ModuleList()\n",
        "    for i, size in enumerate(self.layer_size):\n",
        "      self.conv1ds.append(nn.Conv1d(in_channels= self.field_nums[-1] * self.field_nums[0], out_channels= size, kernel_size= 1))\n",
        "      self.field_nums.append(size)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    batch_size = inputs.shape[0]\n",
        "    dim = inputs.shape[-1]\n",
        "    hidden_nn_layers = [inputs]\n",
        "    final_result = []\n",
        "\n",
        "    for i, size in enumerate(self.layer_size):\n",
        "      # x^(k-1) * x^0\n",
        "      x = torch.einsum('bhd,bmd->bhmd', hidden_nn_layers[-1], hidden_nn_layers[0])\n",
        "      # x.shape = (batch_size , hi * m, dim)\n",
        "      x = x.reshape(batch_size, hidden_nn_layers[-1].shape[1] * hidden_nn_layers[0].shape[1], dim)\n",
        "      # x.shape = (batch_size , hi, dim)\n",
        "      x = self.conv1ds[i](x)\n",
        "\n",
        "      if self.activation is None or self.activation == 'linear':\n",
        "        curr_out = x\n",
        "      else:\n",
        "        curr_out = self.activation(x)\n",
        "\n",
        "      direct_connect = curr_out\n",
        "      next_hidden = curr_out\n",
        "\n",
        "      final_result.append(direct_connect)\n",
        "      hidden_nn_layers.append(next_hidden)\n",
        "\n",
        "    result = torch.cat(final_result, dim=1) # [batch, sum(hi), dim]\n",
        "    result = torch.sum(result, -1)\n",
        "    return result "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrtUzvxDIe78"
      },
      "source": [
        "# 模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBrhA4Xprp1J"
      },
      "source": [
        "class xDeepFM(nn.Module):\n",
        "  def __init__(self, fields, D= 10, layer_size= (128, 128), hidden_dims= (128, 128), n_class= 1, dropout= 0.3): # fields as list \n",
        "    super(xDeepFM, self).__init__()\n",
        "    \"\"\"dense embedding\"\"\"\n",
        "    self.Dense_Embedding= Dense_Embedding(fields= fields, D= D)\n",
        "    \"\"\"mean part\"\"\"\n",
        "    self.b = nn.Parameter(torch.zeros(size= (1, ), dtype= torch.float))\n",
        "    \"\"\"linear part\"\"\"\n",
        "    self.linear = nn.Linear(sum(fields), n_class, bias= False)\n",
        "    \"\"\"CIN part\"\"\"\n",
        "    self.CIN= CIN(field_size= len(fields), layer_size= layer_size)\n",
        "    self.fc= nn.Linear(sum(layer_size), n_class, bias= False)\n",
        "    self.fc_activation= nn.ReLU()\n",
        "    \"\"\"DIN part\"\"\"\n",
        "\n",
        "    layers = []\n",
        "    input_dim = D * len(fields)\n",
        "\n",
        "    for hidden_dim in hidden_dims:\n",
        "      layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "      layers.append(nn.BatchNorm1d(hidden_dim))\n",
        "      layers.append(nn.ReLU())\n",
        "      layers.append(nn.Dropout(p=dropout))\n",
        "      input_dim = hidden_dim\n",
        "    \n",
        "    layers.append(nn.Linear(hidden_dims[-1], n_class))\n",
        "    self.dnn = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, X): # X: [batch_size, d]\n",
        "    \n",
        "    dense_X = self.Dense_Embedding(X) #[batch_size, n_fields, D]\n",
        "    y_linear = self.linear(X)\n",
        "    cin_out = self.CIN(dense_X)\n",
        "    y_cin = self.fc(cin_out)\n",
        "    y_dnn = self.dnn(dense_X.view(-1, dense_X.size()[-1]*dense_X.size()[-2]))\n",
        "    y = y_linear + y_cin + y_dnn + self.b\n",
        "    return self.fc_activation(y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91DMtZHNIm4I"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ6YZYkuIohK",
        "outputId": "fd8c6837-44cf-456f-d3ad-1dbb4a493239"
      },
      "source": [
        "fields = [n_user, n_item] + user_feature_len + item_feature_len\n",
        "print(fields)\n",
        "\n",
        "D = 10\n",
        "hidden_dims = [32]\n",
        "lr = 1e-2\n",
        "n_epoch = 100\n",
        "p = 0.3\n",
        "\n",
        "model = xDeepFM(fields= fields, layer_size= hidden_dims, hidden_dims= hidden_dims, dropout= p).to(device)\n",
        "kf= KFold(n_splits=5)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= lr)\n",
        "# criterion = nn.BCELoss()\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[943, 1682, 8, 21, 18]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5SjXxGeI8B6",
        "outputId": "136f71b5-ce11-4fb6-b9cf-5d8b90d0fcbe"
      },
      "source": [
        "for epoch in range(n_epoch):\n",
        "\n",
        "  RMSEs = []\n",
        "  for train_indice, test_indice in kf.split(X):\n",
        "    a = train_indice\n",
        "    train_X, test_X = X[train_indice], X[test_indice]\n",
        "    '''training process'''\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X= train_X)\n",
        "    # loss = criterion(output.squeeze(dim= 1).cpu(), y_onehot[train_indice])\n",
        "    loss = criterion(output.squeeze(dim= 1).cpu(), y[train_indice])\n",
        "    loss.backward()\n",
        "    # for name, param in model.named_parameters():\n",
        "    #   print(name, param.grad)\n",
        "    optimizer.step()\n",
        "    out = output.squeeze(dim= 1).detach().cpu()\n",
        "    # out_rank = torch.argmax(out, dim=1)+1\n",
        "    rmse = mean_squared_error(out, y[train_indice], squared= False)\n",
        "    # print(f'training rmse: {round(rmse,2)}')\n",
        "\n",
        "    '''testing process'''\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      output = model(X= test_X)\n",
        "      out = output.squeeze(dim= 1).detach().cpu()\n",
        "      # out_rank = torch.argmax(out, dim=1)+1\n",
        "      rmse = mean_squared_error(out, y[test_indice], squared= False)\n",
        "      # print(f'test rmse: {round(rmse, 2)}')\n",
        "      RMSEs.append(rmse)  \n",
        "\n",
        "  if ((epoch+1)% 10) == 0:\n",
        "    print(f'epoch: {epoch+1}')\n",
        "    print(f'training loss: {round(loss.item(), 2)}')\n",
        "    print(f'avg RMSEs: {round(np.mean(RMSEs), 2)}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 10\n",
            "training loss: 0.96\n",
            "avg RMSEs: 0.9700000286102295\n",
            "epoch: 20\n",
            "training loss: 0.85\n",
            "avg RMSEs: 0.9100000262260437\n",
            "epoch: 30\n",
            "training loss: 0.82\n",
            "avg RMSEs: 0.8999999761581421\n",
            "epoch: 40\n",
            "training loss: 0.81\n",
            "avg RMSEs: 0.8999999761581421\n",
            "epoch: 50\n",
            "training loss: 0.79\n",
            "avg RMSEs: 0.8899999856948853\n",
            "epoch: 60\n",
            "training loss: 0.78\n",
            "avg RMSEs: 0.8799999952316284\n",
            "epoch: 70\n",
            "training loss: 0.76\n",
            "avg RMSEs: 0.8700000047683716\n",
            "epoch: 80\n",
            "training loss: 0.74\n",
            "avg RMSEs: 0.8600000143051147\n",
            "epoch: 90\n",
            "training loss: 0.72\n",
            "avg RMSEs: 0.8399999737739563\n",
            "epoch: 100\n",
            "training loss: 0.69\n",
            "avg RMSEs: 0.8299999833106995\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}