{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LinkPrediction_HW2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkNTb4iP_noe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a33ff4f-7f05-4c53-c1d4-877e57a9ebad"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "if torch.__version__.split('+')[0] == '1.8.1':\n",
        "  version = '1.8.0'\n",
        "else:\n",
        "  version = torch.__version__.split('+')[0]\n",
        "print(version)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n",
            "1.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a-vdq4L1gzJ",
        "outputId": "e706ba95-85ec-4a44-ea11-d83a34514e26"
      },
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-{version}+cu101.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-{version}+cu101.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-{version}+cu101.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{version}+cu101.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.6)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.5.9)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (1.6.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.5)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: ase in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.21.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (5.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.8.1+cu101)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.51.2)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ase->torch-geometric) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torch-geometric) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric) (54.2.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric) (0.34.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (0.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzSAOM2x1j5G"
      },
      "source": [
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.utils import degree\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import csv\n",
        "import pandas as pd \n",
        "import copy\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t6baLVS1u5G"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFQj4pnL2fwX"
      },
      "source": [
        "def data_generator(folder = 'dataset1'):\n",
        "  \n",
        "  train_df = pd.read_csv(f'/content/drive/MyDrive/python_data/社群網路與推薦系統/hw2/{folder}/train.csv')\n",
        "  test_df = pd.read_csv(f'/content/drive/MyDrive/python_data/社群網路與推薦系統/hw2/{folder}/test.csv')\n",
        "  content_df = pd.read_csv(f'/content/drive/MyDrive/python_data/社群網路與推薦系統/hw2/{folder}/content.csv', delimiter='\\t', header= None, index_col=[0])\n",
        "\n",
        "  self_train_df = train_df[train_df['to']==train_df['from']]\n",
        "  print(len(self_train_df))\n",
        "  train_df = train_df[train_df['to']!=train_df['from']]\n",
        "\n",
        "  self_test_df = test_df[test_df['to']==test_df['from']]\n",
        "  original_test_df = copy.deepcopy(test_df)\n",
        "  test_df = test_df[test_df['to']!=test_df['from']]\n",
        "\n",
        "  pos_train_df = train_df[train_df['label']== 1]\n",
        "  neg_train_df = train_df[train_df['label']== 0]\n",
        "  print(f'pos len: {len(pos_train_df)}, neg len: {len(neg_train_df)}')\n",
        "  train_pos_edge_index= torch.tensor(pos_train_df[['from', 'to']].to_numpy().transpose(), dtype= torch.long)\n",
        "  train_neg_edge_index= torch.tensor(neg_train_df[['from', 'to']].to_numpy().transpose(), dtype= torch.long)\n",
        "  # print(train_pos_edge_index.shape)\n",
        "  # print(train_neg_edge_index.shape)\n",
        "  x_feature = content_df.sort_index(ascending=True).to_numpy()\n",
        "  print(x_feature.shape)\n",
        "\n",
        "  data = Data(x= x_feature, edge_index=train_pos_edge_index)\n",
        "  data.num_nodes = x_feature.shape[0]\n",
        "  print(data.num_nodes)\n",
        "\n",
        "  test_edge_index = torch.tensor(test_df[['from', 'to']].to_numpy().transpose(), dtype= torch.long)\n",
        "\n",
        "  data.train_pos_edge_index = train_pos_edge_index\n",
        "  ata.train_neg_edge_index = train_neg_edge_index\n",
        "  data.test_edge_index = test_edge_index\n",
        "\n",
        "  return data\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-318wRA6tfQ"
      },
      "source": [
        "import math\n",
        "import random\n",
        "import os.path as osp\n",
        "from itertools import chain\n",
        "import csv\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from scipy.sparse.csgraph import shortest_path\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from torch.nn import ModuleList, Linear, Conv1d, MaxPool1d\n",
        "\n",
        "from torch_geometric.nn import GCNConv, global_sort_pool\n",
        "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
        "from torch_geometric.utils import negative_sampling, add_self_loops, train_test_split_edges, k_hop_subgraph, to_scipy_sparse_matrix"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZGT_U-G6-l1"
      },
      "source": [
        "# Dataset\n",
        "* train_test_split_edges: Splits the edges of a torch_geometric.data.Data object into positive and negative train/val/test edges, and adds attributes of train_pos_edge_index, train_neg_adj_mask, val_pos_edge_index, val_neg_edge_index, test_pos_edge_index, and test_neg_edge_index to data.\n",
        "* negative sampling: Samples random negative edges of a graph given by edge_index.\n",
        "* k_hop_subgraph: Computes the 𝑘-hop subgraph of edge_index around node node_idx. It returns (1) the nodes involved in the subgraph, (2) the filtered edge_index connectivity, (3) the mapping from node indices in node_idx to their new location, and (4) the edge mask indicating which edges were preserved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAAAxBv58b6Q"
      },
      "source": [
        "## Train Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2slke4pp7AJn"
      },
      "source": [
        "# Paper: Link Prediction Based on Graph Neural Networks (NeurIPS 2018)\n",
        "\n",
        "class SEALDataset(InMemoryDataset):\n",
        "  def __init__(self, data, num_hops, split='train', device= 'cpu', attr= False):\n",
        "    self.data = data\n",
        "    self.num_hops = num_hops\n",
        "    self.device= device\n",
        "    self.split= split\n",
        "    self.test_dataset = None \n",
        "    self.attr = attr\n",
        "    super(SEALDataset, self).__init__('../')\n",
        "    index = ['train', 'test'].index(split)\n",
        "    self.data, self.slices = torch.load(self.processed_paths[index])\n",
        "\n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    return ['SEAL_train_data.pt', 'SEAL_test_data.pt']\n",
        "\n",
        "  def process(self):\n",
        "    random.seed(12345)\n",
        "    torch.manual_seed(12345)\n",
        "    \n",
        "    self.__max_z__ = 0\n",
        "\n",
        "    train_pos_list = self.extract_enclosing_subgraphs(\n",
        "        self.data.train_pos_edge_index, self.data['edge_index'], 1)\n",
        "    train_neg_list = self.extract_enclosing_subgraphs(\n",
        "        self.data.train_neg_edge_index, self.data['edge_index'], 0)\n",
        "    \n",
        "    if self.attr:\n",
        "      for data in chain(train_pos_list, train_neg_list):\n",
        "        data.x = torch.cat([torch.tensor(data.x).to(self.device), F.one_hot(data.z, self.__max_z__ + 1).to(torch.float).to(self.device)], axis= 1)\n",
        "    else:\n",
        "      for data in chain(train_pos_list, train_neg_list):\n",
        "        data.x = F.one_hot(data.z, self.__max_z__ + 1).to(torch.float).to(self.device)\n",
        "\n",
        "    torch.save(self.collate(train_pos_list + train_neg_list), self.processed_paths[0])\n",
        "\n",
        "    return None\n",
        "\n",
        "  def extract_enclosing_subgraphs(self, link_index, edge_index, y):\n",
        "    data_list = []\n",
        "    for src, dst in link_index.t().tolist():\n",
        "      sub_nodes, sub_edge_index, mapping, _ = k_hop_subgraph(\n",
        "          [src, dst], self.num_hops, edge_index, relabel_nodes=True)\n",
        "      src, dst = mapping.tolist() # the mapping from node indices in node_idx to their new location\n",
        "\n",
        "      # Remove target link from the subgraph.\n",
        "      mask1 = (sub_edge_index[0] != src) | (sub_edge_index[1] != dst)\n",
        "      mask2 = (sub_edge_index[0] != dst) | (sub_edge_index[1] != src)\n",
        "      sub_edge_index = sub_edge_index[:, mask1 & mask2]\n",
        "\n",
        "      # Calculate node labeling.\n",
        "      z = self.drnl_node_labeling(sub_edge_index, src, dst, num_nodes=sub_nodes.size(0))\n",
        "\n",
        "      data = Data(x=self.data.x[sub_nodes], z=z, edge_index=sub_edge_index, y=y)\n",
        "      data_list.append(data)\n",
        "\n",
        "    return data_list\n",
        "\n",
        "  def drnl_node_labeling(self, edge_index, src, dst, num_nodes=None):\n",
        "    # Double-radius node labeling (DRNL).\n",
        "    src, dst = (dst, src) if src > dst else (src, dst)\n",
        "    adj = to_scipy_sparse_matrix(edge_index, num_nodes=num_nodes).tocsr()\n",
        "\n",
        "    idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
        "    adj_wo_src = adj[idx, :][:, idx]\n",
        "\n",
        "    idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
        "    adj_wo_dst = adj[idx, :][:, idx]\n",
        "\n",
        "    dist2src = shortest_path(adj_wo_dst, directed=False, unweighted=True,\n",
        "                              indices=src)\n",
        "    dist2src = np.insert(dist2src, dst, 0, axis=0)\n",
        "    dist2src = torch.from_numpy(dist2src)\n",
        "\n",
        "    dist2dst = shortest_path(adj_wo_src, directed=False, unweighted=True,\n",
        "                              indices=dst - 1)\n",
        "    dist2dst = np.insert(dist2dst, src, 0, axis=0)\n",
        "    dist2dst = torch.from_numpy(dist2dst)\n",
        "\n",
        "    dist = dist2src + dist2dst\n",
        "    dist_over_2, dist_mod_2 = dist // 2, dist % 2\n",
        "\n",
        "    z = 1 + torch.min(dist2src, dist2dst)\n",
        "    z += dist_over_2 * (dist_over_2 + dist_mod_2 - 1)\n",
        "    z[src] = 1.\n",
        "    z[dst] = 1.\n",
        "    z[torch.isnan(z)] = 0.\n",
        "\n",
        "    self.__max_z__ = max(int(z.max()), self.__max_z__)\n",
        "\n",
        "    return z.to(torch.long)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSlmatA5lNEH"
      },
      "source": [
        "## Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl8vNMkZaUjh"
      },
      "source": [
        "class TestDataset():\n",
        "  def __init__(self, data, num_hops, device= 'cpu', attr= False):\n",
        "    self.data = data\n",
        "    self.num_hops = num_hops\n",
        "    self.device= device\n",
        "    self.attr= attr\n",
        "\n",
        "  def process(self):\n",
        "    random.seed(12345)\n",
        "    torch.manual_seed(12345)\n",
        "    \n",
        "    self.__max_z__ = 0\n",
        "    \n",
        "    test_list = self.extract_enclosing_subgraphs(\n",
        "        self.data.test_edge_index, self.data['edge_index'])\n",
        "    \n",
        "    if self.attr:\n",
        "      for data in test_list:\n",
        "        data.x = torch.cat([torch.tensor(data.x).to(self.device), F.one_hot(data.z, self.__max_z__ + 1).to(torch.float).to(self.device)], axis= 1)\n",
        "    else:\n",
        "      for data in test_list:\n",
        "        data.x = F.one_hot(data.z, self.__max_z__ + 1).to(torch.float).to(self.device)\n",
        "    \n",
        "    return test_list\n",
        "\n",
        "  def extract_enclosing_subgraphs(self, link_index, edge_index):\n",
        "    data_list = []\n",
        "    for src, dst in link_index.t().tolist():\n",
        "      # print(f'src dst: {src}, {dst}')\n",
        "      sub_nodes, sub_edge_index, mapping, _ = k_hop_subgraph(\n",
        "          [src, dst], self.num_hops, edge_index, relabel_nodes=True, num_nodes= self.data.num_nodes)\n",
        "      src, dst = mapping.tolist() # the mapping from node indices in node_idx to their new location\n",
        "      # print(f'src dst mapped: {src},{dst}')\n",
        "      # Remove target link from the subgraph.\n",
        "      mask1 = (sub_edge_index[0] != src) | (sub_edge_index[1] != dst)\n",
        "      mask2 = (sub_edge_index[0] != dst) | (sub_edge_index[1] != src)\n",
        "      sub_edge_index = sub_edge_index[:, mask1 & mask2]\n",
        "\n",
        "      # Calculate node labeling.\n",
        "      z = self.drnl_node_labeling(sub_edge_index, src, dst, num_nodes=sub_nodes.size(0))\n",
        "\n",
        "      data = Data(x=self.data.x[sub_nodes], z=z, edge_index=sub_edge_index)\n",
        "      data_list.append(data)\n",
        "\n",
        "    return data_list\n",
        "\n",
        "  def drnl_node_labeling(self, edge_index, src, dst, num_nodes=None):\n",
        "    # Double-radius node labeling (DRNL).\n",
        "    src, dst = (dst, src) if src > dst else (src, dst)\n",
        "    adj = to_scipy_sparse_matrix(edge_index, num_nodes=num_nodes).tocsr()\n",
        "\n",
        "    idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
        "    adj_wo_src = adj[idx, :][:, idx]\n",
        "\n",
        "    idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
        "    adj_wo_dst = adj[idx, :][:, idx]\n",
        "\n",
        "    dist2src = shortest_path(adj_wo_dst, directed=False, unweighted=True,\n",
        "                              indices=src)\n",
        "    dist2src = np.insert(dist2src, dst, 0, axis=0)\n",
        "    dist2src = torch.from_numpy(dist2src)\n",
        "\n",
        "    dist2dst = shortest_path(adj_wo_src, directed=False, unweighted=True,\n",
        "                              indices=dst - 1)\n",
        "    dist2dst = np.insert(dist2dst, src, 0, axis=0)\n",
        "    dist2dst = torch.from_numpy(dist2dst)\n",
        "\n",
        "    dist = dist2src + dist2dst\n",
        "    dist_over_2, dist_mod_2 = dist // 2, dist % 2\n",
        "\n",
        "    z = 1 + torch.min(dist2src, dist2dst)\n",
        "    z += dist_over_2 * (dist_over_2 + dist_mod_2 - 1)\n",
        "    z[src] = 1.\n",
        "    z[dst] = 1.\n",
        "    z[torch.isnan(z)] = 0.\n",
        "\n",
        "    self.__max_z__ = max(int(z.max()), self.__max_z__)\n",
        "\n",
        "    return z.to(torch.long)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuIdjEcP1w5k"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkcjepLh1yVw"
      },
      "source": [
        "class DGCNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, num_layers, GNN=GCNConv, k=0.6):\n",
        "        super(DGCNN, self).__init__()\n",
        "\n",
        "        if k < 1:  # Transform percentile to number.\n",
        "            num_nodes = sorted([data.num_nodes for data in train_dataset])\n",
        "            k = num_nodes[int(math.ceil(k * len(num_nodes))) - 1]\n",
        "            k = max(10, k)\n",
        "        self.k = int(k)\n",
        "\n",
        "        self.convs = ModuleList()\n",
        "        self.convs.append(GNN(train_dataset.num_features, hidden_channels))\n",
        "        for i in range(0, num_layers - 1):\n",
        "            self.convs.append(GNN(hidden_channels, hidden_channels))\n",
        "        self.convs.append(GNN(hidden_channels, 1))\n",
        "\n",
        "        conv1d_channels = [16, 32]\n",
        "        total_latent_dim = hidden_channels * num_layers + 1\n",
        "        conv1d_kws = [total_latent_dim, 5]\n",
        "        self.conv1 = Conv1d(1, conv1d_channels[0], conv1d_kws[0],\n",
        "                            conv1d_kws[0])\n",
        "        self.maxpool1d = MaxPool1d(2, 2)\n",
        "        self.conv2 = Conv1d(conv1d_channels[0], conv1d_channels[1],\n",
        "                            conv1d_kws[1], 1)\n",
        "        dense_dim = int((self.k - 2) / 2 + 1)\n",
        "        dense_dim = (dense_dim - conv1d_kws[1] + 1) * conv1d_channels[1]\n",
        "        self.lin1 = Linear(dense_dim, 128)\n",
        "        self.lin2 = Linear(128, 1)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        # print(f'x shape: {x.shape}')\n",
        "        xs = [x]\n",
        "        for conv in self.convs:\n",
        "            xs += [torch.tanh(conv(xs[-1], edge_index))]\n",
        "        x = torch.cat(xs[1:], dim=-1)\n",
        "\n",
        "        # Global pooling.\n",
        "        x = global_sort_pool(x, batch, self.k)\n",
        "        x = x.unsqueeze(1)  # [num_graphs, 1, k * hidden]\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.maxpool1d(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1)  # [num_graphs, dense_dim]\n",
        "\n",
        "        # MLP.\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin2(x)\n",
        "        return x"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL5ozIjs7F3V"
      },
      "source": [
        "# Train & Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMcrVCbtBCWV"
      },
      "source": [
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  y_pred, y_true = [], []\n",
        "  total_loss = 0\n",
        "  for data in train_loader:\n",
        "      data = data.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      logits = model(data.x, data.edge_index, data.batch)\n",
        "      loss = BCEWithLogitsLoss()(logits.view(-1), data.y.to(torch.float))\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss += loss.item() * data.num_graphs\n",
        "      y_pred.append(logits.view(-1).detach().cpu())\n",
        "      y_true.append(data.y.view(-1).detach().cpu().to(torch.float))\n",
        "\n",
        "  return total_loss / len(train_dataset), roc_auc_score(torch.cat(y_true), torch.cat(y_pred))\n",
        "\n",
        "\n",
        "def test(loader):\n",
        "  global model\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    y_pred, y_true = [], []\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        logits = model(data.x, data.edge_index, data.batch)\n",
        "        y_pred.append(logits.view(-1).cpu())\n",
        "        y_true.append(data.y.view(-1).cpu().to(torch.float))\n",
        "\n",
        "  return roc_auc_score(torch.cat(y_true), torch.cat(y_pred))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QArlMV4UiDY"
      },
      "source": [
        "def logits_p(logit):\n",
        "  return 2.71828**logit / (1 + 2.71828**logit)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UymZIItiDn8O"
      },
      "source": [
        "# 參數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WKt0GQdDrFZ"
      },
      "source": [
        "num_hops= 2\n",
        "batch_size= 32\n",
        "hidden_channels= 64\n",
        "num_layers= 3\n",
        "lr= 1e-4\n",
        "num_epoch = 30\n",
        "attr= True\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib0cbbZETySp"
      },
      "source": [
        "def main(folder = 'dataset1'):\n",
        "  \n",
        "  train_df = pd.read_csv(f'/content/drive/MyDrive/python_data/社群網路與推薦系統/hw2/{folder}/train.csv')\n",
        "  test_df = pd.read_csv(f'/content/drive/MyDrive/python_data/社群網路與推薦系統/hw2/{folder}/test.csv')\n",
        "  content_df = pd.read_csv(f'/content/drive/MyDrive/python_data/社群網路與推薦系統/hw2/{folder}/content.csv', delimiter='\\t', header= None, index_col=[0])\n",
        "\n",
        "  self_train_df = train_df[train_df['to']==train_df['from']]\n",
        "  print(len(self_train_df))\n",
        "  train_df = train_df[train_df['to']!=train_df['from']]\n",
        "\n",
        "  self_test_df = test_df[test_df['to']==test_df['from']]\n",
        "  original_test_df = copy.deepcopy(test_df)\n",
        "  test_df = test_df[test_df['to']!=test_df['from']]\n",
        "\n",
        "  pos_train_df = train_df[train_df['label']== 1]\n",
        "  neg_train_df = train_df[train_df['label']== 0]\n",
        "  print(f'pos len: {len(pos_train_df)}, neg len: {len(neg_train_df)}')\n",
        "  train_pos_edge_index= torch.tensor(pos_train_df[['from', 'to']].to_numpy().transpose(), dtype= torch.long)\n",
        "  train_neg_edge_index= torch.tensor(neg_train_df[['from', 'to']].to_numpy().transpose(), dtype= torch.long)\n",
        "  # print(train_pos_edge_index.shape)\n",
        "  # print(train_neg_edge_index.shape)\n",
        "  x_feature = content_df.sort_index(ascending=True).to_numpy()\n",
        "  print(x_feature.shape)\n",
        "\n",
        "  data = Data(x= x_feature, edge_index=train_pos_edge_index)\n",
        "  data.num_nodes = x_feature.shape[0]\n",
        "  print(data.num_nodes)\n",
        "\n",
        "  test_edge_index = torch.tensor(test_df[['from', 'to']].to_numpy().transpose(), dtype= torch.long)\n",
        "\n",
        "  data.train_pos_edge_index = train_pos_edge_index\n",
        "  data.train_neg_edge_index = train_neg_edge_index\n",
        "  data.test_edge_index = test_edge_index\n",
        "\n",
        "  global train_dataset\n",
        "  global train_loader\n",
        "  global model\n",
        "  global optimizer\n",
        "\n",
        "  train_dataset = SEALDataset(data, num_hops= num_hops, split='train', device= device, attr= attr)\n",
        "  test_dataset = TestDataset(data, num_hops=num_hops, device= device, attr= attr).process()\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=1)\n",
        "\n",
        "  model = DGCNN(hidden_channels=hidden_channels, num_layers=num_layers).to(device)\n",
        "  optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
        "\n",
        "  train_auc_list = []\n",
        "  for epoch in range(1, num_epoch+1):\n",
        "    loss, train_auc = train()\n",
        "    train_auc_list.append(train_auc)\n",
        "    print(f'Epoch: {epoch:02d}, Loss: {loss:.3f}, Train: {train_auc:.3f}')\n",
        "  \n",
        "  outputs = []\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader: \n",
        "      data = data.to(device)\n",
        "      logits = model(data.x, data.edge_index, data.batch)\n",
        "      outputs.append(logits_p(logits.cpu().item()))\n",
        "  len(outputs) == len(test_df)\n",
        "\n",
        "  # outputs\n",
        "  count = 0\n",
        "  with open(f'{folder}_output.csv', 'w') as f: \n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['id', 'prob'])\n",
        "    for id in original_test_df['id'].values:\n",
        "      if id in self_test_df['id'].values:\n",
        "        writer.writerow([id, 1])\n",
        "      else:\n",
        "        writer.writerow([id, outputs[count]])\n",
        "        count += 1\n",
        "\n",
        "  return model, train_auc_list"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0XNi9xGD7NG"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPBJ-kClD4Gu"
      },
      "source": [
        "# train_auc_list = []\n",
        "# for epoch in range(1, epoch+1):\n",
        "#   loss, train_auc = train()\n",
        "#   train_auc_list.append(train_auc)\n",
        "#   print(f'Epoch: {epoch:02d}, Loss: {loss:.3f}, Train: {train_auc:.3f}')"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw9Q4lykU5sX",
        "outputId": "ada81fc4-8e59-491d-cee0-25d57f6398d9"
      },
      "source": [
        "folders = ['dataset1', 'dataset2', 'dataset3']\n",
        "train_auc_lists= []\n",
        "for folder in folders:\n",
        "  model, train_auc_list = main(folder= folder)\n",
        "  train_auc_lists.append(train_auc_list)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "pos len: 4324, neg len: 4362\n",
            "(2708, 1433)\n",
            "2708\n",
            "Processing...\n",
            "Done!\n",
            "Epoch: 01, Loss: 0.684, Train: 0.600\n",
            "Epoch: 02, Loss: 0.632, Train: 0.695\n",
            "Epoch: 03, Loss: 0.582, Train: 0.741\n",
            "Epoch: 04, Loss: 0.552, Train: 0.766\n",
            "Epoch: 05, Loss: 0.532, Train: 0.786\n",
            "Epoch: 06, Loss: 0.524, Train: 0.796\n",
            "Epoch: 07, Loss: 0.513, Train: 0.806\n",
            "Epoch: 08, Loss: 0.506, Train: 0.815\n",
            "Epoch: 09, Loss: 0.503, Train: 0.817\n",
            "Epoch: 10, Loss: 0.493, Train: 0.827\n",
            "Epoch: 11, Loss: 0.490, Train: 0.830\n",
            "Epoch: 12, Loss: 0.483, Train: 0.836\n",
            "Epoch: 13, Loss: 0.476, Train: 0.843\n",
            "Epoch: 14, Loss: 0.471, Train: 0.847\n",
            "Epoch: 15, Loss: 0.465, Train: 0.852\n",
            "Epoch: 16, Loss: 0.464, Train: 0.854\n",
            "Epoch: 17, Loss: 0.455, Train: 0.861\n",
            "Epoch: 18, Loss: 0.447, Train: 0.865\n",
            "Epoch: 19, Loss: 0.444, Train: 0.868\n",
            "Epoch: 20, Loss: 0.437, Train: 0.874\n",
            "Epoch: 21, Loss: 0.431, Train: 0.877\n",
            "Epoch: 22, Loss: 0.426, Train: 0.882\n",
            "Epoch: 23, Loss: 0.422, Train: 0.884\n",
            "Epoch: 24, Loss: 0.417, Train: 0.887\n",
            "Epoch: 25, Loss: 0.406, Train: 0.893\n",
            "Epoch: 26, Loss: 0.407, Train: 0.892\n",
            "Epoch: 27, Loss: 0.397, Train: 0.898\n",
            "Epoch: 28, Loss: 0.395, Train: 0.900\n",
            "Epoch: 29, Loss: 0.388, Train: 0.904\n",
            "Epoch: 30, Loss: 0.383, Train: 0.907\n",
            "106\n",
            "pos len: 3630, neg len: 3808\n",
            "(3312, 3703)\n",
            "3312\n",
            "Processing...\n",
            "Done!\n",
            "Epoch: 01, Loss: 0.686, Train: 0.553\n",
            "Epoch: 02, Loss: 0.651, Train: 0.654\n",
            "Epoch: 03, Loss: 0.622, Train: 0.704\n",
            "Epoch: 04, Loss: 0.595, Train: 0.735\n",
            "Epoch: 05, Loss: 0.569, Train: 0.763\n",
            "Epoch: 06, Loss: 0.545, Train: 0.786\n",
            "Epoch: 07, Loss: 0.532, Train: 0.799\n",
            "Epoch: 08, Loss: 0.516, Train: 0.815\n",
            "Epoch: 09, Loss: 0.501, Train: 0.828\n",
            "Epoch: 10, Loss: 0.483, Train: 0.844\n",
            "Epoch: 11, Loss: 0.463, Train: 0.861\n",
            "Epoch: 12, Loss: 0.442, Train: 0.877\n",
            "Epoch: 13, Loss: 0.417, Train: 0.894\n",
            "Epoch: 14, Loss: 0.390, Train: 0.910\n",
            "Epoch: 15, Loss: 0.364, Train: 0.922\n",
            "Epoch: 16, Loss: 0.342, Train: 0.931\n",
            "Epoch: 17, Loss: 0.322, Train: 0.939\n",
            "Epoch: 18, Loss: 0.305, Train: 0.945\n",
            "Epoch: 19, Loss: 0.287, Train: 0.951\n",
            "Epoch: 20, Loss: 0.273, Train: 0.956\n",
            "Epoch: 21, Loss: 0.260, Train: 0.960\n",
            "Epoch: 22, Loss: 0.246, Train: 0.964\n",
            "Epoch: 23, Loss: 0.234, Train: 0.968\n",
            "Epoch: 24, Loss: 0.224, Train: 0.970\n",
            "Epoch: 25, Loss: 0.214, Train: 0.973\n",
            "Epoch: 26, Loss: 0.204, Train: 0.975\n",
            "Epoch: 27, Loss: 0.203, Train: 0.976\n",
            "Epoch: 28, Loss: 0.193, Train: 0.978\n",
            "Epoch: 29, Loss: 0.189, Train: 0.978\n",
            "Epoch: 30, Loss: 0.182, Train: 0.980\n",
            "70\n",
            "pos len: 1203, neg len: 1299\n",
            "(877, 1703)\n",
            "877\n",
            "Processing...\n",
            "Done!\n",
            "Epoch: 01, Loss: 0.690, Train: 0.570\n",
            "Epoch: 02, Loss: 0.670, Train: 0.690\n",
            "Epoch: 03, Loss: 0.642, Train: 0.709\n",
            "Epoch: 04, Loss: 0.615, Train: 0.716\n",
            "Epoch: 05, Loss: 0.590, Train: 0.743\n",
            "Epoch: 06, Loss: 0.575, Train: 0.756\n",
            "Epoch: 07, Loss: 0.560, Train: 0.775\n",
            "Epoch: 08, Loss: 0.549, Train: 0.790\n",
            "Epoch: 09, Loss: 0.534, Train: 0.809\n",
            "Epoch: 10, Loss: 0.525, Train: 0.812\n",
            "Epoch: 11, Loss: 0.510, Train: 0.829\n",
            "Epoch: 12, Loss: 0.497, Train: 0.841\n",
            "Epoch: 13, Loss: 0.479, Train: 0.854\n",
            "Epoch: 14, Loss: 0.471, Train: 0.858\n",
            "Epoch: 15, Loss: 0.457, Train: 0.866\n",
            "Epoch: 16, Loss: 0.447, Train: 0.874\n",
            "Epoch: 17, Loss: 0.432, Train: 0.881\n",
            "Epoch: 18, Loss: 0.423, Train: 0.889\n",
            "Epoch: 19, Loss: 0.410, Train: 0.894\n",
            "Epoch: 20, Loss: 0.403, Train: 0.899\n",
            "Epoch: 21, Loss: 0.390, Train: 0.906\n",
            "Epoch: 22, Loss: 0.389, Train: 0.906\n",
            "Epoch: 23, Loss: 0.377, Train: 0.912\n",
            "Epoch: 24, Loss: 0.374, Train: 0.912\n",
            "Epoch: 25, Loss: 0.363, Train: 0.919\n",
            "Epoch: 26, Loss: 0.358, Train: 0.921\n",
            "Epoch: 27, Loss: 0.351, Train: 0.925\n",
            "Epoch: 28, Loss: 0.345, Train: 0.929\n",
            "Epoch: 29, Loss: 0.331, Train: 0.934\n",
            "Epoch: 30, Loss: 0.323, Train: 0.937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "RHxPLvSOR4j5",
        "outputId": "aea9d28b-2824-4528-b87b-8b7a7437da7e"
      },
      "source": [
        "plt.plot(list(range(1, num_epoch+1)), train_auc_lists[0], label= 'folder1')\n",
        "plt.plot(list(range(1, num_epoch+1)), train_auc_lists[1], label= 'folder2')\n",
        "plt.plot(list(range(1, num_epoch+1)), train_auc_lists[2], label= 'folder3')\n",
        "plt.title(f'Train AUC')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3RDdHLeNLgp"
      },
      "source": [
        "## Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYCbkNwBNNFh"
      },
      "source": [
        "# outputs = []\n",
        "# model.eval()\n",
        "# with torch.no_grad():\n",
        "#   for data in test_loader: \n",
        "#     data = data.to(device)\n",
        "#     logits = model(data.x, data.edge_index, data.batch)\n",
        "#     outputs.append(logits_p(logits.cpu().item()))"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKhcC4SQd31v"
      },
      "source": [
        "# len(outputs) == len(test_df)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9arxLqth_uKm"
      },
      "source": [
        "# # outputs\n",
        "# count = 0\n",
        "# with open(f'{folder}_output.csv', 'w') as f: \n",
        "#   writer = csv.writer(f)\n",
        "#   writer.writerow(['id', 'prob'])\n",
        "#   for id in original_test_df['id'].values:\n",
        "#     if id in self_test_df['id'].values:\n",
        "#       writer.writerow([id, 1])\n",
        "#     else:\n",
        "#       writer.writerow([id, outputs[count]])\n",
        "#       count += 1"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c3tLOxKxGwS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iA_yiQ-xKw2"
      },
      "source": [
        "# import torch_geometric.transforms as T\n",
        "# from torch_geometric.nn import GCNConv, GAE, VGAE\n",
        "# from torch_geometric.utils import train_test_split_edges\n",
        "\n",
        "# data.train_mask = data.val_mask = data.test_mask = data.y = data.batch = None\n",
        "# new_data = train_test_split_edges(data)\n",
        "\n",
        "\n",
        "# class GCNEncoder(torch.nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(GCNEncoder, self).__init__()\n",
        "#         self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
        "#         self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True)\n",
        "\n",
        "#     def forward(self, x, edge_index):\n",
        "#         x = self.conv1(x, edge_index).relu()\n",
        "#         return self.conv2(x, edge_index)\n",
        "\n",
        "\n",
        "# class VariationalGCNEncoder(torch.nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(VariationalGCNEncoder, self).__init__()\n",
        "#         self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
        "#         self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
        "#         self.conv_logstd = GCNConv(2 * out_channels, out_channels, cached=True)\n",
        "\n",
        "#     def forward(self, x, edge_index):\n",
        "#         x = self.conv1(x, edge_index).relu()\n",
        "#         return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
        "\n",
        "\n",
        "# class LinearEncoder(torch.nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(LinearEncoder, self).__init__()\n",
        "#         self.conv = GCNConv(in_channels, out_channels, cached=True)\n",
        "\n",
        "#     def forward(self, x, edge_index):\n",
        "#         return self.conv(x, edge_index)\n",
        "\n",
        "\n",
        "# class VariationalLinearEncoder(torch.nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(VariationalLinearEncoder, self).__init__()\n",
        "#         self.conv_mu = GCNConv(in_channels, out_channels, cached=True)\n",
        "#         self.conv_logstd = GCNConv(in_channels, out_channels, cached=True)\n",
        "\n",
        "#     def forward(self, x, edge_index):\n",
        "#         return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R17tuQMj32fx"
      },
      "source": [
        "# variational= False\n",
        "# out_channels = 32\n",
        "# lr= 1e-2\n",
        "# epoch = 100\n",
        "# num_features = data.x.shape[-1]\n",
        "\n",
        "# # if not args.variational:\n",
        "# #     if not args.linear:\n",
        "# #         model = GAE(GCNEncoder(num_features, out_channels))\n",
        "# #     else:\n",
        "# #         model = GAE(LinearEncoder(num_features, out_channels))\n",
        "# # else:\n",
        "# #     if args.linear:\n",
        "# #         model = VGAE(VariationalLinearEncoder(num_features, out_channels))\n",
        "# #     else:\n",
        "# #         model = VGAE(VariationalGCNEncoder(num_features, out_channels))\n",
        "\n",
        "# if variational: \n",
        "#   model = VGAE(VariationalGCNEncoder(num_features, out_channels))\n",
        "# else:\n",
        "#   model = GAE(GCNEncoder(num_features, out_channels))\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = model.to(device)\n",
        "# x = torch.tensor(new_data.x).to(device)\n",
        "# x = x.to(torch.float)\n",
        "# train_pos_edge_index = new_data.train_pos_edge_index.to(device).to(torch.long)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "# def train():\n",
        "#     model.train()\n",
        "#     optimizer.zero_grad()\n",
        "#     z = model.encode(x, train_pos_edge_index)\n",
        "#     loss = model.recon_loss(z, train_pos_edge_index)\n",
        "#     if variational:\n",
        "#       loss = loss + (1 / new_data.num_nodes) * model.kl_loss()\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     return float(loss)\n",
        "\n",
        "\n",
        "# def test(pos_edge_index, neg_edge_index):\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         z = model.encode(x, train_pos_edge_index)\n",
        "#         print(z.size())\n",
        "#     return model.test(z, pos_edge_index, neg_edge_index)\n",
        "\n",
        "\n",
        "# for epoch in range(1, epoch + 1):\n",
        "#     loss = train()\n",
        "#     auc, ap = test(new_data.test_pos_edge_index, new_data.test_neg_edge_index)\n",
        "#     print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjc4P21zzx0u"
      },
      "source": [
        ""
      ],
      "execution_count": 98,
      "outputs": []
    }
  ]
}